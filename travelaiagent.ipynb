{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11409870,"sourceType":"datasetVersion","datasetId":7146885}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TravelAIAgent: Overview â„¹ï¸\nAuthor: Ramis Hasanli  \n[LinkedIn](https://www.linkedin.com/in/hasanliramis/)\\\nDevpost TBA\\\nYouTube Demo TBA\n\nğŸ¤“ Hi Google and learners! Welcome to my submission for the 5-day **Google x Kaggle Generative AI Capstone Project!**\n\n## **TravelAIAgent: A Multimodal Conversational Travel Planner**\n\nIn this project, we build **TravelAIAgent**, a multimodal conversational assistant that helps users plan and enjoy their trips using natural language, photos, and real-time data. It combines intelligent itinerary building, contextual cultural advice, event lookup, photo translation, and user preferences â€” all in a notebook-friendly chatbot you can interact with directly. Just scroll to the bottom to try it out!\n\n---\n\n## ğŸ§  What Problem Does It Solve?\n\nTravelers often bounce between weather apps, ticketing sites, translation tools, and tourist blogs â€” especially when on the go.\n\n**TravelAIAgent simplifies this by acting like a smart, friendly AI travel companion** who:\n- Understands both **natural language** and **tourist photos**\n- Offers **personalized suggestions** based on your preferences\n- Uses **real-time APIs** for weather and events\n- Generates **multi-day travel itineraries**\n- Evaluates its own recommendations with an LLM â€œmeta-checkâ€\n- Summarizes and translates **text in images**\n- Stores helpful memory like your favorite activities or last city\n\n---\n\n## âš™ï¸ How It Works: Architecture & Core Design\n\nThe assistant is built around an **intent-based routing system** that detects what kind of request you're making, and sends it to a specific handler.\n\n### ğŸ”§ Key Components:\n- **Gemini 2.0 Flash + Gemini 1.5 Pro Vision** for all language and image understanding\n- **OpenWeather API** for live and forecasted weather data\n- **Ticketmaster Discovery API** for city events and experiences\n- **ChromaDB + `text-embedding-004`** to deliver grounded cultural tips (RAG-style)\n- **Python CLI Chat Loop** that mimics real chatbot experience in a Kaggle Notebook\n- **Show Markdown Renderer** that formats all AI responses in readable, friendly Markdown\n- **Modular Intent Handlers** like `handle_get_weather`, `handle_plan_itinerary`, etc.\n- **Session Memory** for last city and user travel preferences\n- **LLM-Based Evaluation System** that gives each itinerary a â€œTravel Scoreâ€ and feedback on weather fit, personalization, balance, and authenticity\n\n---\n\n## âœ¨ Functionality\n\nTravelAIAgent supports a wide range of features, including:\n\n- **ğŸŒ¦ Weather Info** â€” current and 5-day forecast using Gemini summaries  \n- **ğŸ§³ Travel & Cultural Tips** â€” grounded tips from 30+ cities via vector search + RAG  \n- **ğŸŸ Event Discovery** â€” find what's happening near you using Ticketmaster API  \n- **ğŸ—º Itinerary Generator** â€” builds personalized plans using your preferences, weather, and events  \n- **ğŸ§  Itinerary Evaluator (Gen AI)** â€” TravelAIAgent self-assesses its own plans with a â€œğŸŒ Travel Scoreâ€ out of 10  \n- **ğŸ–¼ Landmark Descriptions** â€” upload a photo and get a tourist-style explanation  \n- **ğŸ“º YouTube Video Summarizer** â€” provide a chatbot with a video URL to get a summary. Insights are remembered to tailor your itinerary.  \n- **ğŸ“¸ OCR & Translation** â€” extract and translate any text from images (e.g., signs, menus)  \n- **â“ Travel Quiz** â€” answer a few fun questions about your style, budget, and food preferences. Get matched with a perfect destination and a warm explanation of why it suits you.  \n- **ğŸ’¾ Memory** â€” remembers your likes and city history to make smarter suggestions  \n- **ğŸ“ Export Itineraries** â€” choose to save as `.md` or `.pdf` right after generation. It's also possible to export itineraries to `.json` (use `.txt` format for that)  \n- **ğŸ“¤ Export Full Chat History** â€” just type `!export` anytime  \n\n---\n\nNotes:\n- ğŸ›  **Setup required:** Enter your API keys and run all setup cells first.\n- ğŸ“ **Photo processing:** Attach a Kaggle dataset named `photos` for image features to work. Upload photos in .png format. To use photos, reference them by name like \"Hey AI, can you translate the text you see in fileName.png?\", \"What do I see on fileName.png?\", etc.\n- âœ¨ **Export:** Use `!export` to save full chat history or export itineraries post-generation.\n- âŒ **Exit options:** Use `!quit`, `!q`, or `quit` to end the chat.\n\nEnjoy your trip planning with TravelAIAgent in the last section of the notebook named **\"Chat with TravelAIAgent\"** ğŸŒâœˆï¸","metadata":{}},{"cell_type":"markdown","source":"# TravelAIAgent: Setup ğŸ› ï¸\nFirst, install ChromaDB and the Gemini API Python SDK. Then, import all necessary Python dependecies.\n\"reportlab\" is used to generate and export PDF files.\n\"dateparser\" is used to take into consideration user's local timezone","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp\n!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\" \"reportlab\" \"dateparser\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:43:36.766953Z","iopub.execute_input":"2025-04-19T05:43:36.767192Z","iopub.status.idle":"2025-04-19T05:44:21.348732Z","shell.execute_reply.started":"2025-04-19T05:43:36.767163Z","shell.execute_reply":"2025-04-19T05:44:21.347573Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom google.api_core import retry\nfrom IPython.display import HTML, Markdown, display\nimport chromadb\nfrom chromadb.utils.embedding_functions import EmbeddingFunction\nimport os\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\nimport dateparser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:21.351108Z","iopub.execute_input":"2025-04-19T05:44:21.351435Z","iopub.status.idle":"2025-04-19T05:44:24.145854Z","shell.execute_reply.started":"2025-04-19T05:44:21.351406Z","shell.execute_reply":"2025-04-19T05:44:24.144955Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\nfrom google.api_core import retry\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:24.146792Z","iopub.execute_input":"2025-04-19T05:44:24.147225Z","iopub.status.idle":"2025-04-19T05:44:24.153183Z","shell.execute_reply.started":"2025-04-19T05:44:24.147199Z","shell.execute_reply":"2025-04-19T05:44:24.152210Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## ğŸ”‘ API keys\n\nTo run the following cell, your API keys must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`, `WEATHER_API_KEY`, and `EVENTS_API_KEY`.\\\nGOOGLE_API_KEY - Gemini Free API Key. Get it from here: [Gemini API](https://aistudio.google.com/app/u/2/apikey)\\\nWEATHER_API_KEY - OpenWeather Free API Key. Get it from here: [OpenWeather API](https://openweathermap.org/api)\\\nEVENTS_API_KEY - TicketMaster Discovery Free API Key. Get it from here: [TicketMaster API](https://developer.ticketmaster.com/products-and-docs/apis/getting-started/)\\\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret('GOOGLE_API_KEY')\nWEATHER_API_KEY = user_secrets.get_secret('WEATHER_API_KEY')\nEVENTS_API_KEY = user_secrets.get_secret('EVENTS_API_KEY')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:24.154129Z","iopub.execute_input":"2025-04-19T05:44:24.154814Z","iopub.status.idle":"2025-04-19T05:44:24.933373Z","shell.execute_reply.started":"2025-04-19T05:44:24.154784Z","shell.execute_reply":"2025-04-19T05:44:24.932281Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## âœ¨ System Personality and Onboarding\n\nTo create a travel assistant that feels more like a friendly, human travel planner than a generic chatbot, we start by shaping its \"personality\" using system instructions and an engaging onboarding message.\n\n### `TRAVELAGENT_SYSINT` ğŸ§ \n\nThis string defines how our AI should behave during the entire conversation. It's part of Gemini's **system instruction** capability â€” a powerful way to steer tone, style, and behavior of the model. Here, we tell the assistant to act like a friendly, well-traveled guide who gives practical, friendly advice with just the right amount of emojis. It also encourages the bot to remember preferences the user shares and to speak like a helpful person â€” not a robot.\n\nThis instruction is passed into the Gemini API's config to control every future response the assistant generates.\n\n---\n\n### `onboarding_message` ğŸ‘‹\n\nThis is the first message the user sees when launching the chatbot â€” kind of like the assistant's welcome pitch. It sets expectations for what the assistant can help with: weather, tips, events, image translation, itinerary planning, and more. The list-style format, combined with emojis, keeps it light and easy to read. This message is printed to the user and stored in the chat history as the assistant's first message.\n\n---\n\n### âš™ï¸ Connecting to Gemini using genai.Client","metadata":{}},{"cell_type":"code","source":"TRAVELAGENT_SYSINT = (\n    \"You are TravelAIAgent, a helpful and friendly AI travel companion. You're chatting with someone who is planning or enjoying a trip. \"\n    \"Your role is to offer smart, practical advice in a natural, engaging tone â€” like a well-traveled friend or human travel planner. \"\n    \"You assist with weather forecasts, cultural tips, local events, itinerary planning, image/text translation, and tourist insights. \"\n    \"You remember preferences the user shares (like what they enjoy or dislike) and use that to personalize your suggestions. \"\n    \"Be relaxed and human-sounding. Avoid robotic or overly formal language. Use emojis only when they help convey emotion or friendliness. \"\n    \"Offer helpful suggestions based on what the user says â€” but don't overload them with too much info unless they ask for it.\"\n)\n\nonboarding_message = (\n    \"ğŸ‘‹ Hi there! I'm TravelAIAgent â€” your AI-powered companion for smarter travel planning ğŸŒâœˆï¸\\n\\n\"\n    \"Hereâ€™s what I can help you with:\\n\"\n    \"- ğŸŒ¦ï¸ Get real-time weather info and multi-day forecasts for any city\\n\"\n    \"- ğŸ§³ Share cultural tips, local etiquette, and safety advice\\n\"\n    \"- ğŸŒ Translate short phrases or signs into English\\n\"\n    \"- ğŸ“¸ Read and translate text from uploaded travel photos\\n\"\n    \"- ğŸ›ï¸ Describe and answer questions about landmarks in your photos\\n\"\n    \"- ğŸŸï¸ Find events, concerts, and things to do during your trip\\n\"\n    \"- ğŸ—ºï¸ Build a personalized day-by-day travel itinerary using your preferences, the weather, and local events\\n\"\n    \"- ğŸ§  Not sure where to go? Take a quick travel quiz to discover your ideal destination!\\n\\n\"\n    \"ğŸ™‚ Just talk to me naturally â€” what's on your mind? What are your travel preferences? Do you have any travel plans soon?\"\n)\n\n# This block connects the assistant to the Gemini API from Google and sets up the generation behavior. We're using:\n# temperature = 0.7 for a balanced level of creativity and stability â€” just enough flair for conversational responses.\n# max_output_tokens = 512 to limit overly long replies.\n# system_instruction = TRAVELAGENT_SYSINT to ensure every message stays in character as a smart, fun travel companion.\n# This configuration is used in every Gemini content generation call, shaping how the assistant responds to user input throughout the entire experience.\nclient = genai.Client(api_key=GOOGLE_API_KEY)\nconfig = types.GenerateContentConfig(\n    temperature = 0.7,\n    max_output_tokens = 512,\n    system_instruction = TRAVELAGENT_SYSINT,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:24.935664Z","iopub.execute_input":"2025-04-19T05:44:24.935934Z","iopub.status.idle":"2025-04-19T05:44:25.334992Z","shell.execute_reply.started":"2025-04-19T05:44:24.935904Z","shell.execute_reply":"2025-04-19T05:44:25.334222Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# TravelAIAgent: Backend ğŸ§‘â€ğŸ’»","metadata":{}},{"cell_type":"code","source":"# Output formatting + present in Markdown\nfrom IPython.display import display, Markdown, Image\n\ndef show_response(response, label=\"ğŸ¤– TravelAIAgent said\"):\n    # Show label as Markdown header\n    if label:\n        display(Markdown(f\"**{label}:**\"))\n\n    for p in response.parts:\n        if p.text:\n            display(Markdown(p.text))\n        elif p.inline_data:\n            display(Image(p.inline_data.data))\n        else:\n            print(p.to_json_dict())\n\n    display(Markdown('----'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.335833Z","iopub.execute_input":"2025-04-19T05:44:25.336090Z","iopub.status.idle":"2025-04-19T05:44:25.342034Z","shell.execute_reply.started":"2025-04-19T05:44:25.336068Z","shell.execute_reply":"2025-04-19T05:44:25.341255Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## ğŸ§  Interpreting User Intent\nOne of the most important parts of TravelAIAgent is understanding what the user is actually asking for â€” whether they want the weather, cultural tips, a travel itinerary, or help with a photo. To handle this, we use a technique called function routing, powered by Gemini.\n\nThe interpret_user_request() function acts as the brain of this routing system. It sends the user's message to Gemini with a carefully crafted prompt that explains how to classify the input. The prompt includes examples of how to convert natural language into a structured Python dictionary, such as: {'intent': 'get_weather', 'location': 'Paris'} or {'intent': 'plan_itinerary', 'location': 'Rome', 'days': 3, 'when': 'next week'} or {'intent': 'get_tip', 'query': 'public transport in Tokyo'}\n\nGemini then replies with a dictionary string, and we use Pythonâ€™s ast.literal_eval() to safely convert that string into a real Python dictionary. This dictionary tells the assistant which intent to handle, and which handler function to trigger.\nIf something goes wrong â€” such as Gemini returning an invalid dictionary â€” we default to a generic 'chat' intent, so the assistant can still respond gracefully.\n\n---\n\n## ğŸ™ï¸ Extracting City Names\nSometimes users donâ€™t explicitly state a city in a clean format, especially when asking for travel tips or events. To improve contextual understanding, we use the extract_city_from_text() function. This is a lightweight utility that asks Gemini to pull a city name from any given sentence.\n\nFor example:\nâ€œTell me more about Zurichâ€ â†’ returns \"Zurich\", â€œWhat can I do there?â€ â†’ returns \"None\"\n\nIt helps ensure the assistant tracks which city is being discussed, so it can recall that later (e.g. when asked \"What's the weather like there?\"). This adds a subtle layer of memory and personalization to the interaction, without requiring complex NER models or external parsers.","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef interpret_user_request(user_input):\n    prompt = (\n        \"You are a function router. Based on the user message, output ONLY a Python dictionary.\\n\"\n        \"- If the user is asking for weather info, return: {'intent': 'get_weather', 'location': '<CITY>'}\\n\"\n        \"- If the user is asking for tips or local info (scams, etiquette, transport, etc.), return: {'intent': 'get_tip', 'query': '<QUESTION>'}\\n\"\n        \"- If the user asks about the weather in last mentioned city, return: {'intent': 'get_weather_last'}\\n\"\n        \"- If the user asks what city they last mentioned, return: {'intent': 'get_last_city'}\\n\"\n        \"- If the user asks to read and translate a photo, return: {'intent': 'image_translate', 'filename': '<FILENAME>'}\\n\"\n        \"- If the user asks what is shown in a specific photo, return: {'intent': 'describe_photo', 'filename': '<FILENAME>'}\\n\"\n        \"- If the user asks a question about a previously uploaded photo, return: {'intent': 'ask_about_photo', 'question': '<QUESTION>'}\\n\"\n        \"- If the user asks for a travel plan or itinerary, return: {'intent': 'plan_itinerary', 'location': '<CITY>', 'days': <NUMBER>, 'when': '<TIMEFRAME>'}\\n\"\n        \"- If the user asks for weather in the future (e.g. weather next week, forecast for the next few days), return: {'intent': 'get_weather_forecast', 'location': '<CITY>'}\\n\"\n        \"- If the user asks for upcoming events or things to do in a city, return: {'intent': 'get_events', 'location': '<CITY>', 'when': '<TIMEFRAME>'}\\n\"\n        \"- If the user wants a travel quiz, return: {'intent': 'start_quiz'}\\n\"\n        \"- If the user provides a YouTube link to summarize, return: {'intent': 'summarize_yt', 'link': '<YOUTUBE_URL>'}\\n\"\n        \"- Otherwise, return: {'intent': 'chat'}\\n\"\n        \"Respond with ONLY the dictionary. No explanations, no code blocks.\\n\\n\"\n        f\"User: {user_input}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    try:\n        return ast.literal_eval(response.text.strip())\n    except Exception:\n        return {'intent': 'chat'}\n\n\ndef extract_city_from_text(user_input: str) -> str | None:\n    prompt = (\n        \"You are a city name extractor. If the following sentence clearly refers to a known city, \"\n        \"output ONLY the city name as a string, with no extra text.\\n\"\n        \"If no city is clearly mentioned, output 'None'.\\n\\n\"\n        f\"Sentence: {user_input}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    result = response.text.strip().strip(\"'\\\"\")\n    return None if result.lower() == \"none\" else result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.342936Z","iopub.execute_input":"2025-04-19T05:44:25.343158Z","iopub.status.idle":"2025-04-19T05:44:25.364973Z","shell.execute_reply.started":"2025-04-19T05:44:25.343138Z","shell.execute_reply":"2025-04-19T05:44:25.364061Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## ğŸŒ¦ï¸ Real-Time & Forecasted Weather\nTravelAIAgent helps users make smart decisions while traveling â€” and weather is a big part of that! These two functions (get_weather and get_weather_summary) fetch and summarize weather data in a friendly, travel-savvy tone using a combination of the OpenWeather API and Gemini 2.0 Flash.\n\n**get_weather(city) â€“ Current Conditions**\\\nThis function fetches the real-time weather for a given city using the OpenWeather API. Instead of just dumping raw data, it prepares a natural-language summary with the help of Gemini. The API response is parsed to extract key weather details like: Current temperature, Feels-like temperature, Humidity, Wind speed, General weather description. Then, a prompt is crafted to instruct Gemini to summarize this like a local travel agent would â€” conversational, helpful, and using emojis where appropriate.\\\nFor example:\nâ€œItâ€™s around 15Â°C in Lisbon right now with a nice breeze and clear skies â€” perfect for walking the old town! ğŸŒ¤ï¸ğŸ‘Ÿâ€\nThis makes the response feel more human and trip-relevant, not just like reading numbers.\n\n**get_weather_summary(city) â€“ 5-Day Forecast**\\\nInstead of a snapshot, this function gathers a multi-day forecast from OpenWeather, broken into 3-hour segments across five days. The forecast entries are grouped by date, and then passed to Gemini in a structured format. The LLM is asked to: Summarize the general vibe of each day, highlight rain or great outdoor weather, and recommend the best days for activities. This is especially useful when building itineraries, since it helps the assistant match sunny days with walking tours or outdoor activities, and reserve indoor options for rainy ones.\\\nFor example:\nâ€œTuesday looks rainy ğŸŒ§ï¸ â€” maybe plan some museum time. But Wednesday through Friday look warm and mostly sunny â€” great for beach walks or sightseeing! â˜€ï¸ğŸŒŠâ€","metadata":{}},{"cell_type":"code","source":"# Get weather info\nimport requests\nimport datetime\n\n# Current weather\ndef get_weather(city):\n    url = (\n        f\"http://api.openweathermap.org/data/2.5/weather?\"\n        f\"q={city}&appid={WEATHER_API_KEY}&units=metric\"\n    )\n    response = requests.get(url)\n    if response.status_code != 200:\n        return f\"Sorry, I couldnâ€™t fetch the weather for {city}.\"\n\n    data = response.json()\n    description = data[\"weather\"][0][\"description\"]\n    temp = data[\"main\"][\"temp\"]\n    feels_like = data[\"main\"][\"feels_like\"]\n    humidity = data[\"main\"].get(\"humidity\", \"N/A\")\n    wind_speed = data[\"wind\"].get(\"speed\", \"N/A\")\n\n    # Create input for Gemini summarization\n    weather_text = (\n        f\"City: {city}\\n\"\n        f\"Description: {description}\\n\"\n        f\"Temperature: {temp}Â°C (feels like {feels_like}Â°C)\\n\"\n        f\"Humidity: {humidity}%\\n\"\n        f\"Wind Speed: {wind_speed} m/s\"\n    )\n\n    prompt = (\n    \"You are a friendly travel assistant. Provide a helpful, natural-sounding weather update using the info below. \"\n    \"Avoid starting with words like 'Okay' or 'Sure'. Jump right into the useful information. \"\n    \"Use emojis to enhance clarity (e.g. â˜€ï¸, ğŸŒ§ï¸, â˜ï¸), but keep it concise and focused on what the user would want to know for outdoor plans.\\n\\n\"\n    f\"{weather_text}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return response.text.strip()\n\n\n# Future forecast\ndef get_weather_summary(city: str) -> str:\n    url = (\n        f\"http://api.openweathermap.org/data/2.5/forecast?\"\n        f\"q={city}&appid={WEATHER_API_KEY}&units=metric\"\n    )\n    response = requests.get(url)\n    if response.status_code != 200:\n        return f\"Sorry, I couldnâ€™t fetch the forecast for {city}.\"\n\n    data = response.json()\n\n    # Group by date\n    forecasts_by_day = {}\n    for entry in data[\"list\"]:\n        dt = datetime.datetime.fromtimestamp(entry[\"dt\"])\n        date_str = dt.date().isoformat()\n        time_str = dt.strftime(\"%H:%M\")\n        desc = entry[\"weather\"][0][\"description\"]\n        temp = entry[\"main\"][\"temp\"]\n\n        if date_str not in forecasts_by_day:\n            forecasts_by_day[date_str] = []\n        forecasts_by_day[date_str].append(f\"{time_str}: {desc}, {temp:.1f}Â°C\")\n\n    # Prepare text for Gemini to summarize\n    forecast_text = f\"City: {city}\\nForecast for the next 5 days:\\n\\n\"\n    for date, slots in forecasts_by_day.items():\n        forecast_text += f\"Date: {date}\\n\" + \"\\n\".join(f\"  - {slot}\" for slot in slots) + \"\\n\\n\"\n\n    # Ask Gemini to summarize it in a friendly way\n    prompt = (\n    f\"You are a helpful travel assistant writing a casual, friendly 5-day forecast summary for {city}. \"\n    f\"Do not start with phrases like 'Okay' or 'Here's'. Just summarize clearly and naturally. \"\n    f\"Highlight which days are good for exploring outdoors and which might need a rain plan. \"\n    f\"Use emojis (like â˜€ï¸, ğŸŒ§ï¸, ğŸŒ¬ï¸) to represent weather patterns, but donâ€™t overdo it.\\n\\n{forecast_text}\"\n    )\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return response.text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.365927Z","iopub.execute_input":"2025-04-19T05:44:25.366172Z","iopub.status.idle":"2025-04-19T05:44:25.392390Z","shell.execute_reply.started":"2025-04-19T05:44:25.366147Z","shell.execute_reply":"2025-04-19T05:44:25.391361Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## ğŸ–¼ï¸ Understanding & Translating Travel Photos\n\nTravelers often encounter signs, menus, landmarks, and cultural artifacts they donâ€™t fully understand. These three functions add powerful image understanding capabilities to TravelAIAgent by leveraging Gemini 1.5 Pro Vision for visual tasks and Gemini 2.0 Flash for language translation. The result is a travel assistant that can read and interpret photos like a human guide would.\\\n**User can upload photos (.png) to Kaggle dataseet named \"photos\" and attach it to this notebook. This will allow Travel Agent to interact with photos. To reference the photo in chat, user needs to use followig format \"imgName.png\". For example: Translate the text from the picture RoseGarden.png**\n\n**extract_text_from_image(file_path) â€“ OCR with Gemini Vision** ğŸ“·ğŸ”¤\\\nThis function allows users to upload an image (like a street sign, museum label, or food menu), and have the assistant extract all visible text from it. It uses Gemini 1.5 Proâ€™s multimodal vision model, which is capable of reading embedded text from real-world photos.\\\nThe function opens the image file in binary mode, attaches it to a prompt asking Gemini to extract all visible text (but not translate), and then returns the raw string. This step is useful when the goal is to understand whatâ€™s written in a local language before translating or explaining it.\n\n**translate_to_english(text) â€“ Text Translation** ğŸŒğŸ—£ï¸\\\nOnce the text is extracted from an image, we pass it to this function, which uses Gemini 2.0 Flash to translate it into English. The prompt is simple and direct: translate the following text.\\\nThis lets users take photos of signs, menus, schedules, or maps and instantly understand what they mean â€” perfect for tourists navigating unfamiliar environments.\\\nFor example: A French street sign like \"Rue des Bourneaux\" â†’ \"Bourneaux Street\"\n\n**describe_photo(file_path) â€“ Landmark and Scene Description** ğŸ›ï¸âœ¨\\\nThis function goes beyond OCR and answers a higher-level question: â€œWhat am I looking at?â€\\\nIt uses Gemini 1.5 Pro to analyze the image and describe the scene, including its possible cultural or historical context. Itâ€™s especially useful for travel photos like landmarks, public art, or architecture. The prompt instructs Gemini to describe whatâ€™s in the image and why it might matter to a traveler â€” similar to how a museum guide or tour book would explain a location.\\\nFor example: Upload a photo of the Eiffel Tower â†’ â€œThis is the Eiffel Tower in Paris, an iconic symbol of France built for the 1889 World's Fairâ€¦â€","metadata":{}},{"cell_type":"markdown","source":"## ğŸŸï¸ Discovering Local Events\nOne of the most exciting travel upgrades in TravelAIAgent is its ability to suggest real events happening in your destination. Whether youâ€™re into concerts, theater, or cultural exhibits, the assistant uses this function to bring your itinerary to life with up-to-date entertainment options â€” all powered by the Ticketmaster Discovery API and summarized naturally using Gemini.\n\n**get_events(city, start_date, end_date, max_events) â€“ Event Discovery + Summarization**\\\nThis function starts by querying the Ticketmaster Discovery API, using the name of the city and optional start/end date filters. It returns a list of upcoming events sorted by date â€” concerts, sports, exhibitions, shows, and more. We limit the number of results using max_events (default is 5) to avoid overwhelming the user and focus on the most relevant options. For each event, we extract key info such as name, date, venue\\\nInstead of listing raw data directly to the user, the assistant passes the list to Gemini 2.0 Flash using a well-crafted prompt. Gemini then summarizes the events in a casual, friendly tone â€” just like a travel agent would.\\\nFor example: â€œThis week in San Francisco: balloon art exhibits, jazz at Birdland, and some Broadway action if youâ€™re feeling theatrical. ğŸ·ğŸ­â€\\\nThe prompt also nudges Gemini to recommend which events suit different travelers (families, art lovers, music fans), highlight variety and uniqueness, and keep the tone fun and helpful","metadata":{}},{"cell_type":"code","source":"def get_events(city: str, start_date: str = None, end_date: str = None, max_events: int = 5) -> str:\n    url = \"https://app.ticketmaster.com/discovery/v2/events.json\"\n\n    params = {\n        \"apikey\": EVENTS_API_KEY,\n        \"city\": city,\n        \"sort\": \"date,asc\",\n        \"size\" : 20,\n        \"locale\": \"*\",\n    }\n\n    if start_date:\n        params[\"startDateTime\"] = start_date\n    if end_date:\n        params[\"endDateTime\"] = end_date\n\n    response = requests.get(url, params=params)\n    if response.status_code != 200:\n        return f\"Sorry, I couldn't fetch events for {city}.\"\n\n    data = response.json()\n    events_raw = data.get(\"_embedded\", {}).get(\"events\", [])\n    \n    if not events_raw:\n        return f\"No upcoming events found in {city}.\"\n    \n    # Limit and structure relevant events\n    events = []\n    for event in events_raw:\n        name = event.get(\"name\", \"Unnamed Event\")\n        date = event.get(\"dates\", {}).get(\"start\", {}).get(\"localDate\", \"Unknown Date\")\n        venue = event.get(\"_embedded\", {}).get(\"venues\", [{}])[0].get(\"name\", \"Unknown Venue\")\n        link = event.get(\"url\", \"No URL provided\")\n        line = f\"{name} on {date} at {venue} â€” {link}\"\n        events.append(line)\n        if len(events) >= max_events:\n            break\n    \n    # Format for Gemini prompt\n    event_input = \"\\n\".join(events)\n\n\n    # Gemini prompt\n    prompt = (\n    f\"You are a helpful travel assistant creating a local events guide for someone visiting {city}. \"\n    f\"Do not start with phrases like 'Hey there' or 'Okay'. Be informative and concise, like a local giving advice to a friend. \"\n    f\"Highlight 3â€“5 events worth checking out based on variety (music, comedy, sports, festivals). \"\n    f\"For each, explain why it's interesting or who might enjoy it. Include any ticket URLs at the end of the line for convenience.\\n\\n\"\n    f\"Events:\\n{event_input}\"\n    )\n\n\n    summary_response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return summary_response.text.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.393658Z","iopub.execute_input":"2025-04-19T05:44:25.393943Z","iopub.status.idle":"2025-04-19T05:44:25.413634Z","shell.execute_reply.started":"2025-04-19T05:44:25.393923Z","shell.execute_reply":"2025-04-19T05:44:25.412681Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## ğŸ” Local Insights & Landmark Knowledge\nTo give TravelAIAgent the ability to answer grounded, location-specific questions â€” like cultural etiquette, local dos and don'ts, or tips about a photo â€” we use Retrieval Augmented Generation (RAG). This section combines ChromaDB (a vector database), Gemini embeddings, and Gemini's language generation to bring real-world knowledge into the assistant's responses.\n\n**ğŸ§³ documents â€“ Curated Travel Tips**\\\nWe start with a hardcoded list of helpful, city-specific cultural tips and travel advice. These act as a lightweight knowledge base. Each item is a short, practical sentence â€” perfect for answering questions like: â€œWhat should I know before going to Tokyo?â€, â€œIs it okay to haggle in Marrakech?â€\n\n**ğŸ§  GeminiEmbeddingFunction â€“ Semantic Understanding**\\\nTo search through these tips in a meaningful way, we embed both the tips and the user's queries using Gemini's text-embedding-004 model. This converts text into high-dimensional vectors that capture their semantic meaning. The class supports two modes: \"retrieval_document\" â€“ for indexing passages and \"retrieval_query\" â€“ for embedding the user's question. This ensures the model can retrieve relevant advice even if the user asks in a different phrasing than whatâ€™s stored.\n\n**ğŸ—ƒï¸ chroma_client + chromaDB â€“ Embedding Storage**\\\nWe initialize a ChromaDB collection named \"travel_tips\", embed the list of tips, and store them by unique IDs. This allows the assistant to quickly search for tips that are most relevant to the user's question at runtime.\n\n**â“ search_and_answer(user_question) â€“ RAG Answering**\\\nWhen a user asks for tips or cultural context: The function switches to query mode -> Finds the top 2 semantically similar tips from ChromaDB -> Passes those into Gemini 2.0 Flash using a prompt that instructs it to generate a helpful, grounded answer. This pattern ensures that answers are both relevant and informed by the actual data â€” a key aspect of building trust in AI assistants. In case of missing suggestion for particular city, the function asks LLM to provide user with tips.\n\n**ğŸ–¼ï¸ Image Insights: photo_collection + search_photo_insights()**\\\nWe use the same RAG pipeline to store and query descriptions of user-uploaded photos (e.g. landmarks, statues, monuments). After describing a photo using Gemini Vision, the description is embedded and added to a separate collection (photo_insights). Then, if the user asks: â€œWhat is that building?â€ or â€œWhatâ€™s the story behind this statue?â€. We use search_photo_insights() to pull relevant image descriptions from the vector DB and let Gemini answer based on that context.\n\nTogether, these components turn your assistant into a context-aware, grounded travel expert. It can recall city-specific etiquette, offer photo-based insight, and explain things like a human guide â€” all while staying efficient and scalable. âœˆï¸ğŸ§ ğŸ“¸","metadata":{}},{"cell_type":"code","source":"documents = [\n    \"In Bangkok, visit Chatuchak Market on the weekend and avoid tuk-tuk scams near tourist spots. Street food is exceptionalâ€”try mango sticky rice and pad thai. Use BTS Skytrain to avoid traffic.\",\n    \"In Paris, always greet with 'Bonjour' before asking questions. Most museums are closed on Mondays. Book Eiffel Tower and Louvre tickets in advance. Avoid dining near major tourist spots for better food and prices.\",\n    \"In London, public transport uses contactless cards. Tipping is not expected in pubs. Visit museums like the British Museum and Natural History Museumâ€”theyâ€™re free. Pack for rain regardless of season.\",\n    \"In Dubai, public displays of affection are discouraged. Dress modestly in public areas. Visit Burj Khalifa at sunset and try desert safaris. Alcohol is only served in licensed venues.\",\n    \"In Singapore, chewing gum is banned. Itâ€™s one of the cleanest and safest cities globally. Hawker centers offer world-class cheap foodâ€”try chicken rice. Tap water is safe to drink.\",\n    \"In Kuala Lumpur, try nasi lemak for breakfast. Petronas Towers are best viewed at sunset. Use Grab for rides instead of taxis. Shopping malls like Pavilion are top-rated for both locals and tourists.\",\n    \"In New York City, walk fast, tip 15â€“20%, and explore boroughs beyond Manhattan. The subway runs 24/7 but can be confusingâ€”use apps like Citymapper. Times Square is worth seeing once, but avoid eating there.\",\n    \"In Istanbul, try local ferry rides and visit both European and Asian sides of the city. Explore the Grand Bazaar, Hagia Sophia, and enjoy Turkish tea culture. Carry cash for smaller shops.\",\n    \"In Tokyo, avoid loud phone calls on trains. Convenience stores (konbini) have everything. Use IC cards like Suica for transit. Respect local customsâ€”bow slightly when greeting.\",\n    \"In Antalya, the old town (KaleiÃ§i) is walkable and filled with ancient Roman ruins. Visit nearby beaches like Lara and KonyaaltÄ±. Summer gets hotâ€”carry water and wear sunscreen.\",\n    \"In Seoul, Korean street food markets like Gwangjang are must-visit. Public transport is efficient. Use T-Money cards for metro and buses. Donâ€™t tipâ€”it's not customary.\",\n    \"In Rome, beware of pickpockets at popular landmarks. Tap water is drinkable. Visit the Colosseum and Vatican early. Restaurants often charge a 'coperto'â€”a cover charge.\",\n    \"In Phuket, island tours are best booked locally. Avoid animal-based attractions. Visit Phi Phi Islands and Big Buddha. Roads can be dangerousâ€”avoid renting scooters unless experienced.\",\n    \"In Mecca, non-Muslims cannot enter the central holy area. Stay hydrated in the heat. Book hotels well in advance during Hajj and Ramadan. Respect local customs strictly.\",\n    \"In Hong Kong, use the Octopus card for transport and street food. Don't miss Victoria Peak. Enjoy dim sum culture and visit outlying islands like Lantau. Be aware of political sensitivities.\",\n    \"In Barcelona, be cautious of pickpockets on Las Ramblas. Tapas culture is bigâ€”dine late. Visit Sagrada Familia and Park GÃ¼ell. Siesta hours may affect shop openings in afternoons.\",\n    \"In Zurich, trains are punctual to the minute. Public water fountains offer safe drinking water. Switzerland is expensiveâ€”budget accordingly. Visit Lake Zurich and nearby mountains.\",\n    \"In Cairo, tipping (baksheesh) is expected for most services. Visit the pyramids early to avoid crowds. Use Uber instead of taxis for safety and transparency. Dress modestly.\",\n    \"In Sydney, sun protection is essential year-round. Use an Opal card for public transport. Bondi and Manly beaches are popular. Tap water is safe, and coffee culture is strong.\",\n    \"In Marrakech, haggle respectfully in souks. Fridays are holyâ€”many shops may close. Visit Jardin Majorelle and stay in a traditional riad. Dress modestly and be cautious with street guides.\",\n    \"In Amsterdam, watch for bikes at crossings. Many museums require advance reservations. Try local foods like stroopwafels and herring. Public transport is efficient and bike-friendly.\",\n    \"In Mexico City, avoid tap water. Street tacos are a must, but go where locals eat. Visit Frida Kahlo Museum and Teotihuacan pyramids. Altitude can affect visitorsâ€”hydrate well.\",\n    \"In Athens, the Acropolis is best visited early morning. Tipping is appreciated but not required. Enjoy Greek tavernas and try souvlaki and moussaka. Avoid drivingâ€”traffic is chaotic.\",\n    \"In Vancouver, use contactless or Compass Card for transit. Pack for rain, even in summer. Stanley Park and Granville Island are must-visits. Tap water is clean and cold year-round.\",\n    \"In Buenos Aires, late dinners and tango shows are local staples. Beware of counterfeit currency. Palermo is a trendy neighborhood for food and nightlife. Learn basic Spanish phrases.\",\n    \"In Prague, the Old Town is stunning but crowdedâ€”explore Å½iÅ¾kov and LetnÃ¡ for a local vibe. Czech beer is famous and cheap. Public transport is reliableâ€”get a travel pass.\",\n    \"In Vienna, classical concerts abound, but dress semi-formally. Public transport is safe and clean. Visit SchÃ¶nbrunn Palace and try Sachertorte. Tap water comes straight from the Alps.\",\n    \"In Cape Town, avoid walking after dark in certain areas. Visit Table Mountain on a clear day. Enjoy coastal drives like Chapmanâ€™s Peak. Check safety alerts before hiking or beach trips.\",\n    \"In Lisbon, trams can get crowdedâ€”beware of pickpockets. Try pastel de nata from local bakeries. Visit BelÃ©m Tower and ride Tram 28. Hills are steepâ€”wear good shoes.\",\n    \"In Los Angeles, public transport is limitedâ€”consider renting a car. Tipping is standard at 20%. Visit Griffith Observatory, Venice Beach, and explore neighborhoods like Silver Lake and Santa Monica.\",\n    \"In Orlando, most visit for theme parks like Disney World and Universal. Summer is hot and humidâ€”stay hydrated. Lines can be longâ€”use mobile apps to plan attractions.\",\n    \"In Las Vegas, casinos and shows dominate the Strip. Stay indoors during midday heat. Tipping is expected everywhere. Off-strip spots often offer better value and local experiences.\",\n    \"In Miami, visit South Beach for nightlife and Wynwood for street art. Sunscreen is a must. Tap water is safe, and many locals speak Spanish fluently.\",\n    \"In San Francisco, wear layers due to rapid weather changes. Use MUNI and BART for transport. Avoid leaving valuables in cars. Visit Alcatraz and walk the Golden Gate Bridge.\",\n    \"In Chicago, deep-dish pizza is iconic. The 'L' train system is easy to use. Visit Millennium Park and the Art Institute. Winters are freezingâ€”dress in layers.\",\n    \"In Washington D.C., museums are free and top-notchâ€”visit the Smithsonian. Metro is clean but avoid peak hours. Security is tight near landmarks. Cherry blossom season is very popular.\",\n    \"In Boston, Freedom Trail offers a walk through history. Public transport is called the T. Locals are passionate about sportsâ€”catch a Red Sox game if possible.\",\n    \"In Honolulu, beaches like Waikiki are iconic. Respect native Hawaiian culture. Sunscreen with reef-safe ingredients is encouraged. Hiking trails offer scenic ocean views.\",\n    \"In San Diego, the weather is almost always perfect. Visit Balboa Park and La Jolla Cove. Public beaches are clean and accessible. Try fish tacos from local spots.\",\n    \"In New Orleans, music and food culture are unmatched. Visit the French Quarter but be cautious late at night. Try beignets and gumbo. Respect local traditions and celebrations.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.414580Z","iopub.execute_input":"2025-04-19T05:44:25.414805Z","iopub.status.idle":"2025-04-19T05:44:25.438529Z","shell.execute_reply.started":"2025-04-19T05:44:25.414787Z","shell.execute_reply":"2025-04-19T05:44:25.437471Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Gemini Embedding Function class\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input):\n        task_type = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(task_type=task_type)\n        )\n        return [e.values for e in response.embeddings]\n\n# Initialize ChromaDB\nchroma_client = chromadb.Client()\nDB_NAME = \"travel_tips\"\nembed_fn = GeminiEmbeddingFunction()\n\ndb = chroma_client.get_or_create_collection(\n    name=DB_NAME,\n    embedding_function=embed_fn\n)\n\n# Store tips\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n\n# Store image description with ChromaDB\nphoto_collection = chroma_client.get_or_create_collection(\n    name=\"photo_insights\",\n    embedding_function=embed_fn\n)\n\ndef add_photo_description_to_chromadb(photo_id: str, description: str):\n    photo_collection.add(\n        documents=[description],\n        ids=[photo_id]\n    )\n\n# Search photo description with a question\ndef search_photo_insights(user_question: str, top_k: int = 2) -> str:\n    embed_fn.document_mode = False  # use query embedding\n\n    results = photo_collection.query(query_texts=[user_question], n_results=top_k)\n    matches = results[\"documents\"][0]\n\n    prompt = (\n        \"You are a helpful travel assistant. Use the following descriptions to answer the user's question.\\n\\n\"\n        f\"QUESTION: {user_question}\\n\"\n    )\n\n    for desc in matches:\n        prompt += f\"DESCRIPTION: {desc.strip()}\\n\"\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n    return response.text.strip()\n\n# Search and answer\ndef search_and_answer(user_question):\n    embed_fn.document_mode = False\n\n    result = db.query(query_texts=[user_question], n_results=2)\n    passages = result.get(\"documents\", [[]])[0]\n\n    # Updated prompt: Always try to help, even if passages are weak\n    prompt = (\n    \"You are a knowledgeable and friendly travel assistant. The user has asked a travel-related question. \"\n    \"Your job is to provide accurate, practical advice without assuming the user is actively traveling. \"\n    \"Do NOT include greetings like 'Okay' or 'Hey there', and do NOT end with phrases like 'Enjoy your trip' or 'Have fun!'. \"\n    \"Avoid enthusiasm unless it helps clarify something. Respond professionally, clearly, and informatively.\\n\\n\"\n    \"You may use the passages below to support your answer, **but only if they are relevant**. If not, give your best response from general travel knowledge.\\n\\n\"\n    f\"USER QUESTION: {user_question}\\n\"\n    )\n\n    for passage in passages:\n        prompt += f\"PASSAGE: {passage.strip()}\\n\"\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return response.text.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:25.439517Z","iopub.execute_input":"2025-04-19T05:44:25.439815Z","iopub.status.idle":"2025-04-19T05:44:27.680552Z","shell.execute_reply.started":"2025-04-19T05:44:25.439787Z","shell.execute_reply":"2025-04-19T05:44:27.679585Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## ğŸ“º YouTube Video Summarizer\n\nTravelAIAgent supports summarizing **YouTube travel vlogs** using Gemini 1.5's advanced **video understanding** capabilities.\n\nUsers can simply paste a **YouTube link** during the chat, and the agent will analyze the video content, generate a clear **summary** of whatâ€™s shown and gighlight **landmarks**, **tips**, and the **overall vibe**. Note that it can take some time for function to run and return the result.\n\nThis summary is not just shown to the user â€” it's also **stored in memory** and used later to personalize:\n- ğŸ—ºï¸ **Itinerary recommendations**\n- ğŸ§³ Cultural suggestions\n- ğŸ§  Any other responses involving that destination","metadata":{}},{"cell_type":"code","source":"def summarize_yt(youtube_link):\n   # Prepare youtube video using the provided link\n   youtube_video = types.Part.from_uri(\n       file_uri=youtube_link,\n       mime_type=\"video/*\",\n   )\n\n   # Prepare content to send to the model\n   contents = [\n       youtube_video,\n       types.Part.from_text(text=\n        \"You are a helpful travel assistant analyzing a YouTube travel video. \"\n        \"Generate a concise, friendly summary of what's happening in the video. \"\n        \"Highlight the vibe, key activities, places shown, any local tips mentioned, or travel advice given. \"\n        \"Avoid greetings or introductions. Do not reference the video directly. \"\n        \"Write naturally, as if youâ€™re sharing helpful insight with a traveler who hasnâ€™t watched the video but might be inspired by it.\"),\n   ]\n\n   # Define content configuration\n   generate_content_config = types.GenerateContentConfig(\n       temperature = 1,\n       top_p = 0.95,\n       max_output_tokens = 8192,\n       response_modalities = [\"TEXT\"],\n   )\n\n   return client.models.generate_content(\n       model = \"gemini-1.5-pro-latest\",\n       contents = contents,\n       config = generate_content_config,).text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:27.681507Z","iopub.execute_input":"2025-04-19T05:44:27.681777Z","iopub.status.idle":"2025-04-19T05:44:27.688063Z","shell.execute_reply.started":"2025-04-19T05:44:27.681755Z","shell.execute_reply":"2025-04-19T05:44:27.687074Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## ğŸ§  Modular Intent Handlers\nTo keep TravelAIAgent organized and extensible, every user intent is handled by a dedicated function â€” known as a â€œhandler.â€ These functions make the assistant more maintainable and allow for clear separation of logic, especially when integrating multiple tools like weather APIs, image understanding, vector search, and LLM generation.\\\nEach handler performs three key tasks:\n1. Executes a specific capability (like getting weather or generating an itinerary)\n2. Updates the assistantâ€™s memory if needed (e.g. storing the last mentioned city)\n3. Prints and stores the response in the conversation history\n\n---\n\n**ğŸŒ¤ï¸ handle_get_weather & handle_get_weather_forecast**\\\nThese handlers fetch current conditions or a 5-day forecast from OpenWeather and summarize it using Gemini. They store the city as memory[\"last_city\"] so the assistant can reference it later when the user says, â€œWhatâ€™s the weather like there?â€\n\n**ğŸ§³ handle_get_tip**\\\nThis pulls grounded cultural advice from ChromaDB using a RAG-style query. It also extracts and stores the city mentioned in the userâ€™s tip-related question to maintain context.\n\n**ğŸ“¸ handle_describe_photo, handle_ask_about_photo, handle_image_translate**\\\nThese three handlers handle photo-related requests:\n1. describe_photo: Uses Gemini Vision to describe whatâ€™s in an uploaded image (e.g. a statue or landmark)\n2. ask_about_photo: Allows follow-up questions using photo-based RAG from ChromaDB\n3. image_translate: Extracts and translates visible text from a photo (e.g. street signs or menus)\nThey help users understand and interact with their surroundings more easily, especially in unfamiliar places.\n\n**ğŸŒ† handle_get_events**\\\nThis fetches events in a city using the Ticketmaster Discovery API and summarizes them using Gemini. The results feel natural and tailored â€” great for finding things to do on the fly.\n\n**ğŸ§  handle_get_weather_last & handle_get_last_city**\\\nThese support context-awareness. If the user asks: â€œWhatâ€™s the weather like there?â€ or â€œWhich city was I talking about?â€. The assistant responds intelligently based on the memory dictionary (memory[\"last_city\"]), maintaining a natural and coherent conversation flow.\n\n**ğŸ“º handle_summarize_youtube**\\\nThis handler brings video understanding to TravelAIAgent by enabling users to submit a YouTube link â€” usually a travel vlog or destination video â€” and receive a smart, friendly summary of its content:\n1. The video is passed to Gemini 1.5's video understanding API via `summarize_yt(link)`.\n2. Gemini generates a high-level summary.\n3. The summary is then shown to the user in a clean Markdown format.\n4. Itâ€™s saved in memory as `memory[\"video_summary\"]` so it can **personalize future itineraries**.\n\n---\n\nğŸ§  **LLM-Based Self-Evaluation**: After the itinerary is generated, TravelAIAgent passes it back to Gemini for **self-assessment**. The model scores the itinerary on:\n- Balance between indoor/outdoor activities\n- Cultural authenticity\n- Weather suitability\n- Personalization based on your preferences\n\nGemini then responds with a ğŸŒ **Travel Score out of 10**, plus helpful feedback. This makes it easy for users to assess the quality of the plan, catch gaps, and get suggestions â€” making the experience more trustworthy and intelligent.\n\n**ğŸ—ºï¸ handle_plan_itinerary**\nThis is one of the most impressive handlers â€” it builds a personalized, multi-day itinerary by combining:\n\n1. ğŸŒ¦ï¸ Real-time multi-day **weather forecasts**\n2. ğŸ§³ Cultural **travel tips** retrieved using **ChromaDB + Gemini embeddings**\n3. ğŸ’¬ **User preferences** (gathered naturally during conversation and stored in memory)\n4. ğŸŸï¸ Local **event listings** using the Ticketmaster Discovery API\n\nThe handler intelligently estimates the trip start date based on natural language like \"next week\" or \"this weekend\", and then assembles all relevant information into a prompt that Gemini uses to generate a highly tailored itinerary.\n\n---\n\nâœ¨ **Export Features**: After generating the itinerary, the user is automatically asked whether they'd like to export it. If yes, the plan and evaluation can be saved in:\n- ğŸ“„ **Markdown format (.md)**\n- ğŸ“„ **PDF format** (beautifully rendered with basic formatting)\n- The bot also supports a `!export` command at any time during the session to export the entire **chat history** (including both user inputs and AI responses) into a `.md` file. This makes it easy to revisit recommendations, itinerary details, or planning discussions.\n- When exporting the itinerary to a file, user **must** include the format of a file in a filename i.e **travelItinerary.md** or **travelItinerary.pdf**\n","metadata":{}},{"cell_type":"code","source":"import json\n# Handlers\ndef handle_get_weather(action, history, memory):\n    city = action[\"location\"]\n    memory[\"last_city\"] = city\n    weather_info = get_weather(city)\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=weather_info)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=weather_info)]))\n\ndef handle_get_tip(action, history, memory):\n    query = action[\"query\"]\n    city = extract_city_from_text(query)\n    memory[\"last_city\"] = city if city else query\n    tip_answer = search_and_answer(query)\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=tip_answer)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=tip_answer)]))\n\ndef handle_describe_photo(action, history):\n    filename = action[\"filename\"]\n    filepath = f\"/kaggle/input/photos/{filename}\"\n\n    try:\n        with open(filepath, \"rb\") as f:\n            f.read(1)\n        if filename not in photo_collection.get()['ids']:\n            description = describe_photo(filepath)\n            add_photo_description_to_chromadb(photo_id=filename, description=description)\n            show_response(types.ModelContent(parts=[types.Part.from_text(text=description)]))\n            history.append(types.ModelContent(parts=[types.Part.from_text(text=description)]))\n        else:\n            print(f\"ğŸ¤– TravelAIAgent: I already have a description for `{filename}`.\")\n    except FileNotFoundError:\n        print(f\"ğŸ¤– TravelAIAgent: I couldn't find the image `{filename}` in /kaggle/input/photos/.\")\n\ndef handle_ask_about_photo(user_input, history):\n    if not photo_collection.get()['documents']:\n        print(\"ğŸ¤– TravelAIAgent: I havenâ€™t analyzed any photos yet. Ask me to describe one first.\")\n        return\n    photo_answer = search_photo_insights(user_input)\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=photo_answer)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=photo_answer)]))\n\n\ndef handle_image_translate(action, history):\n    filename = action[\"filename\"]\n    filepath = f\"/kaggle/input/photos/{filename}\"\n\n    try:\n        raw_text = extract_text_from_image(filepath)\n        if not raw_text or raw_text.lower() in [\"none\", \"\"]:\n            print(\"ğŸ¤– TravelAIAgent: I couldn't read any text from the image.\")\n            return\n\n        translated = translate_to_english(raw_text)\n        show_response(types.ModelContent(parts=[types.Part.from_text(text=translated)]))\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=translated)]))\n    except FileNotFoundError:\n        print(f\"ğŸ¤– TravelAIAgent: I couldn't find `{filename}`. Upload it to /kaggle/input/photos/.\")\n\ndef handle_get_weather_last(memory, history):\n    if memory[\"last_city\"]:\n        city = memory[\"last_city\"]\n        weather_info = get_weather(city)\n        print(f\"ğŸ¤– TravelAIAgent: Here's the latest weather in {city}:\\n{weather_info}\")\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=weather_info)]))\n    else:\n        print(\"ğŸ¤– TravelAIAgent: I don't know your last mentioned city yet.\")\n\ndef handle_get_last_city(memory, history):\n    if memory[\"last_city\"]:\n        print(f\"ğŸ¤– TravelAIAgent: The last city you mentioned was {memory['last_city']}.\")\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=memory['last_city'])]))\n    else:\n        print(\"ğŸ¤– TravelAIAgent: You haven't mentioned a city yet.\")\n\ndef handle_get_weather_forecast(action, memory, history):\n    city = action[\"location\"]\n    memory[\"last_city\"] = city\n    forecast = get_weather_summary(city)\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=forecast)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=forecast)]))\n\n# Get events info\ndef handle_get_events(action, history, memory):\n    import dateparser\n    import pytz\n    from datetime import datetime, timedelta  # âœ… Properly import timedelta\n\n    city = action.get(\"location\", \"Unknown location\")\n    when_raw = action.get(\"when\") or \"this week\"\n    when = when_raw.lower()\n    memory[\"last_city\"] = city\n\n    local_tz = pytz.timezone(\"US/Pacific\")  # Or adapt to the user's timezone if needed\n    today = datetime.now(local_tz)\n\n    # ğŸ§  Try to parse specific date from natural language (e.g., \"April 23\")\n    parsed_date = dateparser.parse(when_raw)\n\n    if parsed_date and parsed_date.date() > today.date():\n        # User provided a specific future date like \"April 23\"\n        start_day = parsed_date\n        end_day = parsed_date\n    elif \"tomorrow\" in when:\n        start_day = today + timedelta(days=1)\n        end_day = start_day\n    elif \"weekend\" in when:\n        days_until_saturday = (5 - today.weekday()) % 7\n        start_day = today + timedelta(days=days_until_saturday)\n        end_day = start_day + timedelta(days=1)\n    elif \"next week\" in when:\n        start_day = today + timedelta(days=(7 - today.weekday()))\n        end_day = start_day + timedelta(days=6)\n    elif \"next month\" in when:\n        start_day = today + timedelta(days=30)\n        end_day = start_day + timedelta(days=7)\n    elif \"today\" in when:\n        start_day = today\n        end_day = today\n    else:\n        start_day = today\n        end_day = today + timedelta(days=7)\n\n    # Format Ticketmaster-compatible ISO8601 date range\n    start = start_day.strftime(\"%Y-%m-%dT00:00:00Z\")\n    end = end_day.strftime(\"%Y-%m-%dT23:59:59Z\")\n\n    # Fetch and show\n    events_info = get_events(city=city, start_date=start, end_date=end)\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=events_info)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=events_info)]))\n\n# YouTube summarizer\ndef handle_summarize_youtube(link, history, memory):\n    try:\n        summary = summarize_yt(link)\n        show_response(types.ModelContent(parts=[types.Part.from_text(text=summary)]))\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=summary)]))\n        # Save it to memory for itinerary use\n        memory[\"video_summary\"] = summary\n    except Exception as e:\n        print(\"âš ï¸ Error summarizing YouTube video:\", e)\n\n# EVALUATE TRAVEL ITINERARY\ndef evaluate_itinerary(itinerary: str, user_prefs: str) -> str:\n    examples = (\n        \"EXAMPLE 1:\\n\"\n        \"ITINERARY:\\n\"\n        \"Day 1: Outdoor walking tour during heavy rain\\n\"\n        \"Day 2: Multiple museums with little cultural connection to location\\n\"\n        \"Day 3: No events or food exploration\\n\"\n        \"EVALUATION:\\n\"\n        \"âš ï¸ Travel Score: 5/10. Too much outdoor activity in poor weather. Lack of cultural/local engagement.\\n\\n\"\n        \"EXAMPLE 2:\\n\"\n        \"ITINERARY:\\n\"\n        \"Day 1: Market tour + indoor museum during rainy day\\n\"\n        \"Day 2: Outdoor gardens during sunshine + local food tour\\n\"\n        \"Day 3: Art gallery and live event matching preferences\\n\"\n        \"EVALUATION:\\n\"\n        \"âœ… Travel Score: 9/10. Well-balanced mix of indoor/outdoor. Great alignment with user preferences and local experience.\\n\\n\"\n    )\n\n    prompt = (\n    \"You are an AI travel evaluator who just generated the itinerary below. \"\n    \"Now reflect on it and provide a friendly, useful critique that would help the user decide how good this itinerary is.\\n\\n\"\n    \"Start with a short message explaining that this is a self-assessment, then output:\\n\"\n    \"ğŸŒ Travel Score: X/10\\n\\n\"\n    \"Then include comments on:\\n\"\n    \"- Day balance (indoor vs outdoor)\\n\"\n    \"- Local authenticity\\n\"\n    \"- Suitability to weather\\n\"\n    \"- Personalization to preferences\\n\\n\"\n    f\"USER PREFERENCES:\\n{user_prefs}\\n\\n\"\n    f\"ITINERARY:\\n{itinerary}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n    return response.text.strip()\n\n# Create and present travel itinerary\ndef handle_plan_itinerary(action, memory, history):\n    city = action.get(\"location\", \"Unknown location\")\n    when = (action.get(\"when\") or \"today\").lower()\n    days = action.get(\"days\")\n\n    # Safe fallback if days is None or not a number\n    if not isinstance(days, int):\n        if \"tomorrow\" in when:\n            days = 2\n        elif \"weekend\" in when:\n            days = 2\n        elif \"week\" in when:\n            days = 5\n        elif \"month\" in when:\n            days = 7\n        else:\n            days = 3  # default fallback\n\n    memory[\"last_city\"] = city\n\n    today = datetime.datetime.utcnow()\n    if \"tomorrow\" in when:\n        start_day = today + datetime.timedelta(days=1)\n    elif \"next week\" in when:\n        start_day = today + datetime.timedelta(days=7)\n    elif \"next month\" in when:\n        start_day = today + datetime.timedelta(days=30)\n    elif \"weekend\" in when:\n        start_day = today + datetime.timedelta(days=(5 - today.weekday()) % 7)  # next Saturday\n    else:\n        start_day = today  # default\n\n    start_date = start_day.strftime(\"%Y-%m-%dT00:00:00Z\")\n    end_day = start_day + datetime.timedelta(days=days)\n    end_date = end_day.strftime(\"%Y-%m-%dT23:59:59Z\")\n\n    # Get forecast summary\n    forecast = get_weather_summary(city)\n    # Get cultural tips\n    tips = search_and_answer(f\"travel tips for {city}\")\n    # Get relevant events\n    events = get_events(city=city, start_date=start_date, end_date=end_date, max_events=5)\n    # Get user preferences\n    user_prefs = \"\\n\".join(memory[\"preferences\"]) if memory[\"preferences\"] else \"No specific preferences given.\"\n    # Get vlog summary\n    video_summary = memory.get(\"video_summary\", \"\")\n\n    # Build prompt\n    prompt = (\n        f\"You are a friendly travel planner. Create a detailed {days}-day itinerary for a user visiting {city} starting {when if when else 'today'}.\\n\"\n        f\"Use the following information:\\n\\n\"\n        f\"Weather:\\n{forecast}\\n\\n\"\n        f\"Cultural Tips:\\n{tips}\\n\\n\"\n        f\"Events:\\n{events}\\n\\n\"\n        f\"User Preferences:\\n{user_prefs}\\n\\n\"\n        f\"Travel Vlog Summary (if any):\\n{video_summary}\\n\\n\"\n        f\"Suggest fun, practical daily plans. If weather is bad, offer indoor options. Use events when relevant. Make it feel personalized and local.\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    itinerary = response.text.strip()\n\n    # Itinerary Evaluation\n    # 1. Evaluate itinerary with LLM\n    evaluation = evaluate_itinerary(itinerary, user_prefs)\n    # 2. Show both\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=itinerary)]))\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=evaluation)]))\n    # 3. Save both to history\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=itinerary)]))\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=evaluation)]))\n    # Ask for export option\n    export_choice = input(\"\\nğŸ“ Export this itinerary? (markdown/pdf/json/none): \").strip().lower()\n\n    city_slug = city.lower().replace(\" \", \"_\")\n    base_filename = f\"itinerary_{city_slug}\"\n\n    if export_choice in [\"markdown\", \"md\"]:\n        filename = input(f\"ğŸ“„ Enter filename (default: {base_filename}.md): \").strip() or f\"{base_filename}.md\"\n        try:\n            with open(filename, \"w\", encoding=\"utf-8\") as f:\n                f.write(f\"# Travel Itinerary for {city.title()}\\n\\n\")\n                f.write(itinerary + \"\\n\\n\")\n                f.write(\"## âœ¨ TravelAIAgent Evaluation\\n\\n\")\n                f.write(evaluation + \"\\n\")\n            print(f\"âœ… Saved to `{filename}`.\")\n        except Exception as e:\n            print(\"âš ï¸ Failed to save .md file:\", str(e))\n\n    elif export_choice == \"pdf\":\n        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n        from reportlab.lib.pagesizes import LETTER\n        from reportlab.lib.styles import getSampleStyleSheet        \n        filename = input(f\"ğŸ“„ Enter filename (default: {base_filename}.pdf): \").strip() or f\"{base_filename}.pdf\"\n        try:\n            doc = SimpleDocTemplate(filename, pagesize=LETTER, rightMargin=40, leftMargin=40, topMargin=40, bottomMargin=40)\n            styles = getSampleStyleSheet()\n            flowables = []\n        \n            # Convert itinerary (Markdown-like) into Paragraphs\n            for line in itinerary.split('\\n'):\n                if line.strip() == \"\":\n                    flowables.append(Spacer(1, 12))\n                else:\n                    flowables.append(Paragraph(line.strip(), styles[\"Normal\"]))\n\n            # Add evaluation section\n            flowables.append(Spacer(1, 24))\n            flowables.append(Paragraph(\"âœ¨ TravelAIAgent Evaluation\", styles[\"Heading2\"]))\n            for line in evaluation.split('\\n'):\n                if line.strip() == \"\":\n                    flowables.append(Spacer(1, 12))\n                else:\n                    flowables.append(Paragraph(line.strip(), styles[\"Normal\"]))\n                    \n            doc.build(flowables)\n            print(f\"âœ… PDF saved as `{filename}`.\")\n        except Exception as e:\n            print(\"âš ï¸ Failed to generate PDF:\", str(e))\n\n    elif export_choice == \"json\":\n        filename = input(f\"ğŸ“„ Enter filename (default: {base_filename}.txt \").strip() or f\"{base_filename}.json\"\n        try:\n            # Structure your output into a dict\n            itinerary_json = {\n                \"city\": city,\n                \"start_date\": start_day.strftime(\"%Y-%m-%d\"),\n                \"days\": days,\n                \"user_preferences\": memory[\"preferences\"],\n                \"raw_itinerary_text\": itinerary,\n                \"travel_score_summary\": evaluation,\n            }\n            with open(filename, \"w\", encoding=\"utf-8\") as f:\n                json.dump(itinerary_json, f, indent=2)\n            print(f\"âœ… JSON saved as `{filename}`.\")\n        except Exception as e:\n            print(\"âš ï¸ Failed to save .json file:\", str(e))\n\n\n    else:\n        print(\"âœ… No problem! Let me know if you want to export later. How can I be more helpful to you?\")\n\n# Export Chat History\ndef export_chat_history(history, filename=\"travel_chat_history.md\"):\n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        for entry in history:\n            if isinstance(entry, types.UserContent):\n                f.write(\"**ğŸ‘¤USER:**\\n\")\n            else:\n                f.write(\"**ğŸ¤–TravelAIAgent:**\\n\")\n            for part in entry.parts:\n                f.write(part.text.strip() + \"\\n\\n\")\n    print(f\"âœ… Chat history exported to {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:27.689169Z","iopub.execute_input":"2025-04-19T05:44:27.689534Z","iopub.status.idle":"2025-04-19T05:44:27.731387Z","shell.execute_reply.started":"2025-04-19T05:44:27.689511Z","shell.execute_reply":"2025-04-19T05:44:27.730304Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## â“ Interactive Travel Quiz","metadata":{}},{"cell_type":"code","source":"def handle_travel_quiz(history, memory):\n    print(\"ğŸ¤– TravelAIAgent: Let's find your perfect travel destination! ğŸŒ Answer a few quick questions.\")\n\n    # Collect quiz preferences\n    quiz_data = {\n        \"vibe\": input(\"Q1: What kind of vibe are you looking for? (Relaxing / Adventurous / Cultural / Party) \").strip(),\n        \"budget\": input(\"Q2: What's your budget like? (Low / Medium / High) \").strip(),\n        \"weather\": input(\"Q3: Preferred climate? (Warm / Cold / Mild / Doesnâ€™t matter) \").strip(),\n        \"food\": input(\"Q4: What type of food do you love? (Seafood / Vegetarian / Street food / Gourmet) \").strip(),\n        \"pace\": input(\"Q5: How fast-paced do you want the trip to feel? (Chill / Balanced / Fast) \").strip(),\n        \"region\": input(\"Q6: Any preferred continent or region? (Europe / Asia / Americas / Doesnâ€™t matter) \").strip(),\n    }\n\n    # Prompt for Gemini\n    quiz_prompt = (\n        \"You are a warm, conversational travel assistant. Based on the following preferences, recommend the perfect city-level travel destination. \"\n        \"Describe your choice in a friendly, paragraph-style explanation as if you're chatting with a curious traveler. \"\n        \"Include reasons that touch on the user's vibe, budget, climate preference, food, pace, and regional interest. \"\n        \"Make the user feel excited about this destination â€” like it's truly meant for them.\\n\\n\"\n        f\"Vibe: {quiz_data['vibe']}\\n\"\n        f\"Budget: {quiz_data['budget']}\\n\"\n        f\"Weather: {quiz_data['weather']}\\n\"\n        f\"Food: {quiz_data['food']}\\n\"\n        f\"Travel Pace: {quiz_data['pace']}\\n\"\n        f\"Preferred Region: {quiz_data['region']}\"\n    )\n\n    # Get Gemini response\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=quiz_prompt)]\n    )\n    reply_text = response.text.strip()\n    show_response(types.ModelContent(parts=[types.Part.from_text(text=reply_text)]))\n\n    # More reliable city extraction\n    city = extract_city_from_text(reply_text)\n    if city:\n        memory[\"last_city\"] = city\n        memory.setdefault(\"preferences\", []).append(f\"Quiz-based recommendation: {city}\")\n\n    # Offer itinerary generation\n    if \"last_city\" in memory:\n        confirm = input(f\"\\nWould you like me to plan a 3-day itinerary for {memory['last_city']}? (yes/no) \").strip().lower()\n        if confirm in [\"yes\", \"y\"]:\n            print(\"âœˆï¸ Awesome! Crafting your personalized adventure...\")\n            action = {'intent': 'plan_itinerary', 'location': memory['last_city'], 'days': 3, 'when': 'next week'}\n            handle_plan_itinerary(action, memory, history)\n        else:\n            print(\"ğŸ‘ No worries! Feel free to ask for trip ideas or advice anytime.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:27.733958Z","iopub.execute_input":"2025-04-19T05:44:27.734235Z","iopub.status.idle":"2025-04-19T05:44:27.754453Z","shell.execute_reply.started":"2025-04-19T05:44:27.734214Z","shell.execute_reply":"2025-04-19T05:44:27.753456Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## ğŸ” **The Main Chat Loop**\nThis block of code powers the entire real-time conversation between the user and TravelAIAgent. Itâ€™s where everything comes together â€” intent recognition, memory tracking, handler dispatching, and fallback chat (Send \"!q\" or \"!quit! or \"quit\" to end chat). Here's how it works:\n\n---\n\n**ğŸ•˜ history and memory Initialization**\\\nThe assistant starts with two critical variables:\n1. history: a list that stores the full back-and-forth conversation (in Geminiâ€™s expected format). It keeps context across turns.\n2. memory: a dictionary that stores session-specific context like: last_city: the most recently mentioned city (used for follow-ups like \"What's the weather like there?\"), and  preferences: any user-specified likes (e.g. â€œI love seafoodâ€) that guide future responses\n\n---\n**ğŸ‘‹ First Impression: Onboarding Message**\\\nThe assistant prints a warm welcome using the onboarding_message and also adds it to the conversation history. This sets the tone and immediately informs the user of the assistantâ€™s capabilities.\n\n---\n\n**ğŸ” The Main Loop**\\\nThis is a while True: loop that simulates ongoing conversation. Each time the user enters input: User message is read and cleaned, and intent is interpreted using interpret_user_request()\n\nThe assistant routes the request to the appropriate handler: Weather, Cultural tips, Photo analysis, Event search, Itinerary planning, Translation, Memory recall, Handlers take care of fetching data, calling APIs, or prompting Gemini, then store the result back in history.\n\n---\n\n**ğŸ§  Fallback Branch**\\\nIf none of the intent matches are triggered (e.g. the user says something casual or vague): The input is added to history, Gemini is called with full context to continue the conversation naturally. Optionally, if the user shares a preference (e.g. \"I love museums\"), itâ€™s stored in memory[\"preferences\"] for future personalization. A try/except block ensures any Gemini API failures are handled gracefully without breaking the loop â€” offering a friendly error instead of a crash.\n","metadata":{}},{"cell_type":"code","source":"def start_travel_chat():\n    history = []\n    memory = {\n        \"last_city\": None,\n        \"preferences\": []\n    }\n    onboarding_block = types.ModelContent(parts=[types.Part.from_text(text=onboarding_message)])\n    history.append(onboarding_block)\n    show_response(onboarding_block)\n    \n    # Main loop\n    while True:\n        user_input = input(\"ğŸ‘¤ You:\").strip()\n        \n        # Menu options\n        # Quit - Use !q, !quit or quit to end the conversation.\n        if user_input.strip().lower() in ['!q', 'quit', '!quit']:\n            print(\"Thanks for using TravelAIAgent. Goodbye!\")\n            break\n\n        # !export - Export chat history\n        if user_input.strip().lower() == \"!export\":\n            filename = f\"travel_chat_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n            export_chat_history(history, filename)\n            continue\n\n        # User actions/requests to LLM\n        action = interpret_user_request(user_input)\n        if action.get(\"intent\") == \"get_weather\" and \"location\" in action:\n            handle_get_weather(action, history, memory)\n        elif action.get(\"intent\") == \"get_tip\" and \"query\" in action:\n            handle_get_tip(action, history, memory)\n        elif action.get(\"intent\") == \"describe_photo\" and \"filename\" in action:\n            handle_describe_photo(action, history)\n        elif action.get(\"intent\") == \"ask_about_photo\" and \"question\" in action:\n            handle_ask_about_photo(user_input, history)\n        elif action.get(\"intent\") == \"image_translate\" and \"filename\" in action:\n            handle_image_translate(action, history)\n        elif action.get(\"intent\") == \"get_weather_last\":\n            handle_get_weather_last(memory, history)\n        elif action.get(\"intent\") == \"get_last_city\":\n            handle_get_last_city(memory, history)\n        elif action.get(\"intent\") == \"get_weather_forecast\" and \"location\" in action:\n            handle_get_weather_forecast(action, memory, history)\n        elif action.get(\"intent\") == \"plan_itinerary\" and \"location\" in action:\n            handle_plan_itinerary(action, memory, history)\n        elif action.get(\"intent\") == \"get_events\" and \"location\" in action:\n            handle_get_events(action, history, memory)\n        elif action.get(\"intent\") == \"summarize_yt\" and \"link\" in action:\n            handle_summarize_youtube(action[\"link\"], history, memory)\n        elif action.get(\"intent\") == \"start_quiz\":\n            handle_travel_quiz(history, memory)\n        else:\n            if user_input:\n                history.append(types.UserContent(parts=[types.Part.from_text(text=user_input)]))\n                if any(phrase in user_input.lower() for phrase in [\"i like\", \"i prefer\", \"i enjoy\", \"i love\", \"i want\"]):\n                    memory[\"preferences\"].append(user_input)\n                try:\n                    response = client.models.generate_content(\n                        model=\"gemini-2.0-flash\",\n                        config=config,\n                        contents=history\n                    )\n                    history.append(response.candidates[0].content)\n                    show_response(response.candidates[0].content)\n                except Exception as e:\n                    print(\"âš ï¸ TravelAIAgent: I had trouble generating a response. Please try rephrasing.\")\n                    print(\"Error:\", str(e))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:27.755511Z","iopub.execute_input":"2025-04-19T05:44:27.755916Z","iopub.status.idle":"2025-04-19T05:44:27.781092Z","shell.execute_reply.started":"2025-04-19T05:44:27.755890Z","shell.execute_reply":"2025-04-19T05:44:27.780355Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# ğŸ’¬ **Chat with TravelAIAgent here!**\nTo begin your travel planning session, click \"Run All\". Type naturally â€” like you're talking to a friend â€” and ask anything about your destination. Type `q` to exit the chat anytime.","metadata":{}},{"cell_type":"code","source":"start_travel_chat()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:44:27.782436Z","iopub.execute_input":"2025-04-19T05:44:27.783341Z","iopub.status.idle":"2025-04-19T05:44:40.455681Z","shell.execute_reply.started":"2025-04-19T05:44:27.783307Z","shell.execute_reply":"2025-04-19T05:44:40.454809Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**ğŸ¤– TravelAIAgent said:**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"ğŸ‘‹ Hi there! I'm TravelAIAgent â€” your AI-powered companion for smarter travel planning ğŸŒâœˆï¸\n\nHereâ€™s what I can help you with:\n- ğŸŒ¦ï¸ Get real-time weather info and multi-day forecasts for any city\n- ğŸ§³ Share cultural tips, local etiquette, and safety advice\n- ğŸŒ Translate short phrases or signs into English\n- ğŸ“¸ Read and translate text from uploaded travel photos\n- ğŸ›ï¸ Describe and answer questions about landmarks in your photos\n- ğŸŸï¸ Find events, concerts, and things to do during your trip\n- ğŸ—ºï¸ Build a personalized day-by-day travel itinerary using your preferences, the weather, and local events\n- ğŸ§  Not sure where to go? Take a quick travel quiz to discover your ideal destination!\n\nğŸ™‚ Just talk to me naturally â€” what's on your mind? What are your travel preferences? Do you have any travel plans soon?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"----"},"metadata":{}},{"output_type":"stream","name":"stdin","text":"ğŸ‘¤ You: Hi how is it going today?\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**ğŸ¤– TravelAIAgent said:**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Hey there! ğŸ‘‹ I'm doing great, thanks for asking! Just here, ready to help make some travel dreams come true. ğŸ˜Š\n\nDo you have any trips on the horizon, or are you just starting to brainstorm? Maybe you're curious about a specific destination? Let me know what's on your mind!\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"----"},"metadata":{}},{"output_type":"stream","name":"stdin","text":"ğŸ‘¤ You: !q\n"},{"name":"stdout","text":"Thanks for using TravelAIAgent. Goodbye!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## ğŸ® Things to Try\n\nHere are some fun and powerful examples of what you can do with **TravelAIAgent**. Make sure to complete the **Setup** section of this notebook before testing:\n\n---\n\nğŸŒ¦ï¸ Weather\n- Ask for the **current weather** in any city  \n  _Example:_ `What's the weather like in Paris right now?`\n\n- Ask for a **weather forecast** for upcoming days  \n  _Example:_ `What's the weather like in Tokyo next week?`\n\nğŸ§³ Travel Tips\n- Ask for **local travel tips, etiquette, or advice**  \n  _Example:_ `What should I know before traveling to Istanbul?`\n\nğŸ–¼ï¸ Image Understanding\n- Upload a photo to the `/kaggle/input/photos/` dataset and ask for a **tourist-style description**  \n  _Example:_ `Whatâ€™s in RoseGarden.png?`\n\n- Upload a photo with a **non-English sign or menu** and ask for a translation  \n  _Example:_ `Can you translate text from \"menu_japan.png\"?`\n\nğŸŸï¸ Events\n- Ask about **events happening today, this weekend, or a specific date**  \n  _Example:_ `What are some events happening in Los Angeles this weekend?`\n\nğŸ’¬ Preferences & Memory\n- Tell the chatbot your **travel style or food preferences**  \n  _Example:_ `I love seafood and art museums.`  \n  _These are remembered and used when building personalized itineraries._\n\nğŸ“º YouTube Video Summarizer  \n- Share a **YouTube link** to a travel vlog or destination video.  \n  The chatbot will **analyze** the video and **summarize** key moments, places visited, the vibe, and tips shared.  \n  This info is **stored in memory** and used later when creating your personalized travel itinerary.\\\n  _Example:_ `Can you summarize this travel video? https://www.youtube.com/watch?v=*********`\n\nğŸ—ºï¸ Itinerary Generation\n- Ask the assistant to generate a **multi-day travel itinerary**  \n  _Example:_ `Create a travel itinerary for Rome for 5 days starting next weekend.`\n\n- After generating the plan, **evaluate it with LLM-powered scoring**  \n  _Example:_ _(done automatically)_ You'll see a ğŸŒ Travel Score with feedback.\n\n- **Export** your generated itinerary in Markdown or PDF format  \n  _When prompted, choose \"markdown\" or \"pdf\" to save the file locally._\n\nğŸ“¤ Chat History Export\n- Type `!export` to save the **entire conversation** (user + AI responses) into a `.md` file  \n  _Great for trip planning logs and sharing!_\n\nğŸ® Travel Quiz  \n- Try the **Travel Quiz** to get a travel recommendation based on your preferences and knowledge.  \n  _Example:_ `Let's take a travel quiz to find my next destination!`","metadata":{}},{"cell_type":"markdown","source":"## ğŸŒ Why This Matters\n\nTravel planning today is fragmented â€” travelers juggle multiple apps for weather, translation, event discovery, local tips, and itinerary building. This project brings everything together into one intelligent, multimodal assistant.\n\n**TravelAIAgent** uses state-of-the-art Generative AI not just to answer questions, but to act like a smart, well-traveled companion. It understands natural language, interprets photos and videos, recommends activities based on real-time data, and even critiques its own suggestions. With features like image OCR, cultural RAG tips, YouTube video summarization, and itinerary evaluation â€” it showcases how GenAI can go beyond chat and solve real-world problems.\n\nThis matters because it demonstrates the future of AI assistants: grounded, contextual, and capable of understanding the world the way humans do â€” through sights, language, experiences, and preferences.\n","metadata":{}},{"cell_type":"markdown","source":"## ğŸª² Limitations and future work\nTravelAIAgent is not perfect and can make mistakes. It learns and becomes better day-by-day. One day it'll be very smart! ğŸ™‚\\\nOverall, it's really good for requests related to current and upcoming day (e.g weather now, events now, itirenary for upcoming 3 days, etc.)\n\n**Bugs:**\\\nEvents:\n- \"What are some events happening in *** this Sunday\" - Can not process \"this Sunday\" properly and falls back to current day.\n- Event handler does not know your current time zone so it might produce confusing results including previous days.\n- Event handler is not able to process multi-day requests, but it will try it's best to do so when generating multi-day itinerary.\n- Event handler might be confused overall with future days. This is because of TicketMaster's API.\n\nItinerary:\n- Itinerary generated by user is not being saved in memory, so if user declines exporting, the itinerary will be lost unless user prompts chatbot to generate a new one.\n\n**Future work:**\n- Printing the results, displaying markdown and memory updates can be streamlined (combined/refactored)\n- Addition of voice input/output\n- Fine-tuning using travel/tourism dataset\n- Implement trip planner\n","metadata":{}},{"cell_type":"markdown","source":"## ğŸ™‹â€â™‚ï¸ Conclusion\n\nTravelAIAgent demonstrates how Generative AI can transform travel planning into a smarter, more personalized experience. By combining language understanding, image and video analysis, real-time APIs, and self-evaluation, this assistant goes beyond simple Q&A â€” it acts as a true travel companion.\n\nFrom recommending events and generating itineraries to translating street signs and summarizing travel vlogs, TravelAIAgent showcases the powerful synergy of multimodal AI and real-world utility.\n\nIt was a truly enriching experience participating in Google's 5-day Gen AI Intensive Course. This intensive program not only introduced me to the fascinating realm of Agentic AI but also equipped me with the essential tools and foundational knowledge to effectively leverage Gemini-powered agents in my own projects.\n\nWorking on this TravelAgentAI LLM assistant within the Kaggle environment has been an exciting journey, and I see tremendous potential for the implementation of these intelligent technologies across various facets of our daily lives. I am deeply grateful to the Google team for providing such comprehensive learning materials and for their ongoing research and development in the field of Agentic AI. Can't wait to use Gemini in my future personal projects!\n\nThank you for exploring this project â€” and bon voyage! âœˆï¸ğŸŒ\\\nSincerely,\\\nRamis Hasanli","metadata":{}}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11394700,"sourceType":"datasetVersion","datasetId":7136311}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TravelAIAgent: Overview ℹ️\nAuthor: Ramis Hasanli\nhttps://www.linkedin.com/in/hasanliramis/\n\nWelcome to my for the 5-day Google x Kaggle Generative AI course!\\\n**TravelAIAgent: A Multimodal Conversational Travel Planner**\\\nIn this project, we build **TravelAIAgent**, a multimodal conversational assistant that helps users plan and enjoy their trips using natural language and photos. It combines real-time weather and event data, image understanding, user preferences, and grounded travel knowledge to deliver an intelligent, personalized travel experience.\n\n## 🧠 What Problem Does It Solve?\n\nPlanning a trip often involves jumping between apps — weather forecasts, events calendars, translation tools, tourist guides, and more. Many travelers also struggle to get real-time, personalized advice while already on the move.\n\n**TravelAIAgent solves this by acting like a smart, always-available travel agent** that:\n- Understands natural language queries and photos\n- Offers contextual suggestions tailored to the user’s preferences\n- Uses real-time data (e.g., events, weather) to enhance planning\n- Generates complete itineraries, answers travel questions, and guides users through unfamiliar locations\n\nThe result is a smoother, more interactive travel experience — whether you're planning in advance or exploring on the go.\n\n---\n\n## ⚙️ How It Works: Architecture and Core Design\n\nThe assistant uses **intent-based routing** to understand what the user is asking, then routes requests to specialized modules that handle tasks like weather forecasting, itinerary generation, photo analysis, and event lookup.\n\n### 🔧 Key Components:\n- **Gemini 2.0 Flash & 1.5 Pro Vision** – for language and image understanding\n- **OpenWeather API** – for current weather and multi-day forecasts\n- **Ticketmaster Discovery API** – to fetch local events\n- **ChromaDB + `text-embedding-004`** – to retrieve grounded cultural tips (RAG)\n- **Python CLI loop** – simulates interactive chat experience (notebook-friendly)\n- **Modular intent handlers** – clean structure to process user requests\n\n---\n\n## ✨ Functionality\n\nTravelAIAgent supports a wide range of features, including:\n\n- **🌦 Real-time weather updates** and multi-day forecasts with Gemini-powered summaries\n- **🧳 Travel tips and cultural insights** for 30+ cities via Retrieval Augmented Generation (RAG)\n- **🎟 Local event discovery** using Ticketmaster's API, summarized by Gemini\n- **🗺 Personalized itinerary generation**, combining forecast, events, travel tips, and user preferences\n- **🖼️ Tourist photo understanding**, including landmark descriptions and cultural context\n- **📸 Text extraction and translation** from uploaded photos (e.g., signs, menus)\n- **🧠 Session memory** of user preferences and previously mentioned cities\n\nAll responses are generated in a natural, friendly tone — just like a helpful travel agent might speak.\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# TravelAIAgent: Setup 🛠️\nFirst, install ChromaDB and the Gemini API Python SDK. Then, import all necessary Python dependecies.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp\n!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom google.api_core import retry\nfrom IPython.display import HTML, Markdown, display\nimport chromadb\nfrom chromadb.utils.embedding_functions import EmbeddingFunction\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Automated retry","metadata":{}},{"cell_type":"code","source":"# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\nfrom google.api_core import retry\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔑 API keys\n\nTo run the following cell, your API keys must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`, `WEATHER_API_KEY`, and `EVENTS_API_KEY`.\\\nGOOGLE_API_KEY - Gemini API Key.\\\nWEATHER_API_KEY - OpenWeather API Key.\\\nEVENTS_API_KEY - TicketMaster Discovery API Key.\\\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret('GOOGLE_API_KEY')\nWEATHER_API_KEY = user_secrets.get_secret('WEATHER_API_KEY')\nEVENTS_API_KEY = user_secrets.get_secret('EVENTS_API_KEY')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✨ System Personality and Onboarding\n\nTo create a travel assistant that feels more like a friendly, human travel planner than a generic chatbot, we start by shaping its \"personality\" using system instructions and an engaging onboarding message.\n\n### `TRAVELAGENT_SYSINT` 🧠\n\nThis string defines how our AI should behave during the entire conversation. It's part of Gemini's **system instruction** capability — a powerful way to steer tone, style, and behavior of the model. Here, we tell the assistant to act like a friendly, well-traveled guide who gives practical, friendly advice with just the right amount of emojis. It also encourages the bot to remember preferences the user shares and to speak like a helpful person — not a robot.\n\nThis instruction is passed into the Gemini API's config to control every future response the assistant generates.\n\n---\n\n### `onboarding_message` 👋\n\nThis is the first message the user sees when launching the chatbot — kind of like the assistant's welcome pitch. It sets expectations for what the assistant can help with: weather, tips, events, image translation, itinerary planning, and more. The list-style format, combined with emojis, keeps it light and easy to read. This message is printed to the user and stored in the chat history as the assistant's first message.\n\n---\n\n### ⚙️ Connecting to Gemini using genai.Client","metadata":{}},{"cell_type":"code","source":"TRAVELAGENT_SYSINT = (\n    \"You are TravelAIAgent, a helpful and friendly AI travel companion. You're chatting with someone who is planning or enjoying a trip. \"\n    \"Your role is to offer smart, practical advice in a natural, engaging tone — like a well-traveled friend or human travel planner. \"\n    \"You assist with weather forecasts, cultural tips, local events, itinerary planning, image/text translation, and tourist insights. \"\n    \"You remember preferences the user shares (like what they enjoy or dislike) and use that to personalize your suggestions. \"\n    \"Be relaxed and human-sounding. Avoid robotic or overly formal language. Use emojis only when they help convey emotion or friendliness. \"\n    \"Offer helpful suggestions based on what the user says — but don't overload them with too much info unless they ask for it.\"\n)\n\nonboarding_message = (\n    \"Hi there! I'm TravelAIAgent — your AI-powered companion for smarter travel planning 🌍✈️\\n\\n\"\n    \"Here’s what I can help you with:\\n\"\n    \"- 🌦️ Get real-time weather info and multi-day forecasts for any city\\n\"\n    \"- 🧳 Share cultural tips, local etiquette, and safety advice\\n\"\n    \"- 🌐 Translate short phrases or signs into English\\n\"\n    \"- 📸 Read and translate text from uploaded travel photos\\n\"\n    \"- 🏛️ Describe and answer questions about landmarks in your photos\\n\"\n    \"- 🎟️ Find events, concerts, and things to do during your trip\\n\"\n    \"- 🗺️ Build a personalized day-by-day travel itinerary using your preferences, the weather, and local events\\n\\n\"\n    \"Just talk to me naturally — what's on your mind?\"\n)\n\n# This block connects the assistant to the Gemini API from Google and sets up the generation behavior. We're using:\n# temperature = 0.7 for a balanced level of creativity and stability — just enough flair for conversational responses.\n# max_output_tokens = 512 to limit overly long replies.\n# system_instruction = TRAVELAGENT_SYSINT to ensure every message stays in character as a smart, fun travel companion.\n# This configuration is used in every Gemini content generation call, shaping how the assistant responds to user input throughout the entire experience.\nclient = genai.Client(api_key=GOOGLE_API_KEY)\nconfig = types.GenerateContentConfig(\n    temperature = 0.7,\n    max_output_tokens = 512,\n    system_instruction = TRAVELAGENT_SYSINT,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TravelAIAgent: Backend 🧑‍💻","metadata":{}},{"cell_type":"markdown","source":"## 🧠 Interpreting User Intent\nOne of the most important parts of TravelAIAgent is understanding what the user is actually asking for — whether they want the weather, cultural tips, a travel itinerary, or help with a photo. To handle this, we use a technique called function routing, powered by Gemini.\n\nThe interpret_user_request() function acts as the brain of this routing system. It sends the user's message to Gemini with a carefully crafted prompt that explains how to classify the input. The prompt includes examples of how to convert natural language into a structured Python dictionary, such as: {'intent': 'get_weather', 'location': 'Paris'} or {'intent': 'plan_itinerary', 'location': 'Rome', 'days': 3, 'when': 'next week'} or {'intent': 'get_tip', 'query': 'public transport in Tokyo'}\n\nGemini then replies with a dictionary string, and we use Python’s ast.literal_eval() to safely convert that string into a real Python dictionary. This dictionary tells the assistant which intent to handle, and which handler function to trigger.\nIf something goes wrong — such as Gemini returning an invalid dictionary — we default to a generic 'chat' intent, so the assistant can still respond gracefully.\n\n---\n\n## 🏙️ Extracting City Names\nSometimes users don’t explicitly state a city in a clean format, especially when asking for travel tips or events. To improve contextual understanding, we use the extract_city_from_text() function. This is a lightweight utility that asks Gemini to pull a city name from any given sentence.\n\nFor example:\n“Tell me more about Zurich” → returns \"Zurich\", “What can I do there?” → returns \"None\"\n\nIt helps ensure the assistant tracks which city is being discussed, so it can recall that later (e.g. when asked \"What's the weather like there?\"). This adds a subtle layer of memory and personalization to the interaction, without requiring complex NER models or external parsers.","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef interpret_user_request(user_input):\n    prompt = (\n        \"You are a function router. Based on the user message, output ONLY a Python dictionary.\\n\"\n        \"- If the user is asking for weather info, return: {'intent': 'get_weather', 'location': '<CITY>'}\\n\"\n        \"- If the user is asking for tips or local info (scams, etiquette, transport, etc.), return: {'intent': 'get_tip', 'query': '<QUESTION>'}\\n\"\n        \"- If the user asks about the weather in last mentioned city, return: {'intent': 'get_weather_last'}\\n\"\n        \"- If the user asks what city they last mentioned, return: {'intent': 'get_last_city'}\\n\"\n        \"- If the user asks to read and translate a photo, return: {'intent': 'image_translate', 'filename': '<FILENAME>'}\\n\"\n        \"- If the user asks what is shown in a specific photo, return: {'intent': 'describe_photo', 'filename': '<FILENAME>'}\\n\"\n        \"- If the user asks a question about a previously uploaded photo, return: {'intent': 'ask_about_photo', 'question': '<QUESTION>'}\\n\"\n        \"- If the user asks for a travel plan or itinerary, return: {'intent': 'plan_itinerary', 'location': '<CITY>', 'days': <NUMBER>, 'when': '<TIMEFRAME>'}\"\n        \"- If the user asks for weather in the future (e.g. weather next week, forecast for the next few days), return: {'intent': 'get_weather_forecast', 'location': '<CITY>'}\\n\"\n        \"- If the user asks for upcoming events or things to do in a city, return: {'intent': 'get_events', 'location': '<CITY>'}\"\n        \"- Otherwise, return: {'intent': 'chat'}\\n\"\n        \"Respond with ONLY the dictionary. No explanations, no code blocks.\\n\\n\"\n        f\"User: {user_input}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    try:\n        return ast.literal_eval(response.text.strip())\n    except Exception:\n        return {'intent': 'chat'}\n\n\ndef extract_city_from_text(user_input: str) -> str | None:\n    prompt = (\n        \"You are a city name extractor. If the following sentence clearly refers to a known city, \"\n        \"output ONLY the city name as a string, with no extra text.\\n\"\n        \"If no city is clearly mentioned, output 'None'.\\n\\n\"\n        f\"Sentence: {user_input}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    result = response.text.strip().strip(\"'\\\"\")\n    return None if result.lower() == \"none\" else result\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🌦️ Real-Time & Forecasted Weather\nTravelAIAgent helps users make smart decisions while traveling — and weather is a big part of that! These two functions (get_weather and get_weather_summary) fetch and summarize weather data in a friendly, travel-savvy tone using a combination of the OpenWeather API and Gemini 2.0 Flash.\n\n**get_weather(city) – Current Conditions**\\\nThis function fetches the real-time weather for a given city using the OpenWeather API. Instead of just dumping raw data, it prepares a natural-language summary with the help of Gemini. The API response is parsed to extract key weather details like: Current temperature, Feels-like temperature, Humidity, Wind speed, General weather description. Then, a prompt is crafted to instruct Gemini to summarize this like a local travel agent would — conversational, helpful, and using emojis where appropriate.\\\nFor example:\n“It’s around 15°C in Lisbon right now with a nice breeze and clear skies — perfect for walking the old town! 🌤️👟”\nThis makes the response feel more human and trip-relevant, not just like reading numbers.\n\n**get_weather_summary(city) – 5-Day Forecast**\\\nInstead of a snapshot, this function gathers a multi-day forecast from OpenWeather, broken into 3-hour segments across five days. The forecast entries are grouped by date, and then passed to Gemini in a structured format. The LLM is asked to: Summarize the general vibe of each day, highlight rain or great outdoor weather, and recommend the best days for activities. This is especially useful when building itineraries, since it helps the assistant match sunny days with walking tours or outdoor activities, and reserve indoor options for rainy ones.\\\nFor example:\n“Tuesday looks rainy 🌧️ — maybe plan some museum time. But Wednesday through Friday look warm and mostly sunny — great for beach walks or sightseeing! ☀️🌊”","metadata":{}},{"cell_type":"code","source":"# Get weather info\nimport requests\nimport datetime\n\n# Current weather\ndef get_weather(city):\n    url = (\n        f\"http://api.openweathermap.org/data/2.5/weather?\"\n        f\"q={city}&appid={WEATHER_API_KEY}&units=metric\"\n    )\n    response = requests.get(url)\n    if response.status_code != 200:\n        return f\"Sorry, I couldn’t fetch the weather for {city}.\"\n\n    data = response.json()\n    description = data[\"weather\"][0][\"description\"]\n    temp = data[\"main\"][\"temp\"]\n    feels_like = data[\"main\"][\"feels_like\"]\n    humidity = data[\"main\"].get(\"humidity\", \"N/A\")\n    wind_speed = data[\"wind\"].get(\"speed\", \"N/A\")\n\n    # Create input for Gemini summarization\n    weather_text = (\n        f\"City: {city}\\n\"\n        f\"Description: {description}\\n\"\n        f\"Temperature: {temp}°C (feels like {feels_like}°C)\\n\"\n        f\"Humidity: {humidity}%\\n\"\n        f\"Wind Speed: {wind_speed} m/s\"\n    )\n\n    prompt = (\n        \"You are a friendly travel agent giving a casual weather update. \"\n        \"Use the details below to tell the user what the weather is like right now and whether it’s good for being outdoors. \"\n        \"Sound conversational, not robotic. Use emojis to represent weather conditions.\\n\\n\"\n        f\"{weather_text}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return response.text.strip()\n\n\n# Future forecast\ndef get_weather_summary(city: str) -> str:\n    url = (\n        f\"http://api.openweathermap.org/data/2.5/forecast?\"\n        f\"q={city}&appid={WEATHER_API_KEY}&units=metric\"\n    )\n    response = requests.get(url)\n    if response.status_code != 200:\n        return f\"Sorry, I couldn’t fetch the forecast for {city}.\"\n\n    data = response.json()\n\n    # Group by date\n    forecasts_by_day = {}\n    for entry in data[\"list\"]:\n        dt = datetime.datetime.fromtimestamp(entry[\"dt\"])\n        date_str = dt.date().isoformat()\n        time_str = dt.strftime(\"%H:%M\")\n        desc = entry[\"weather\"][0][\"description\"]\n        temp = entry[\"main\"][\"temp\"]\n\n        if date_str not in forecasts_by_day:\n            forecasts_by_day[date_str] = []\n        forecasts_by_day[date_str].append(f\"{time_str}: {desc}, {temp:.1f}°C\")\n\n    # Prepare text for Gemini to summarize\n    forecast_text = f\"City: {city}\\nForecast for the next 5 days:\\n\\n\"\n    for date, slots in forecasts_by_day.items():\n        forecast_text += f\"Date: {date}\\n\" + \"\\n\".join(f\"  - {slot}\" for slot in slots) + \"\\n\\n\"\n\n    # Ask Gemini to summarize it in a friendly way\n    prompt = (\n        f\"You’re a helpful travel assistant. Write a casual, helpful summary of this 5-day weather forecast in {city}. \"\n        f\"Include what days look nice for being outdoors, if there’s rain or cold, and suggest the best days to explore. \"\n        f\"Sound like a local giving friendly advice. Use emojis to represent weather conditions.\\n\\n{forecast_text}\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return response.text.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🖼️ Understanding & Translating Travel Photos\n\nTravelers often encounter signs, menus, landmarks, and cultural artifacts they don’t fully understand. These three functions add powerful image understanding capabilities to TravelAIAgent by leveraging Gemini 1.5 Pro Vision for visual tasks and Gemini 2.0 Flash for language translation. The result is a travel assistant that can read and interpret photos like a human guide would.\n\n**extract_text_from_image(file_path) – OCR with Gemini Vision** 📷🔤\\\nThis function allows users to upload an image (like a street sign, museum label, or food menu), and have the assistant extract all visible text from it. It uses Gemini 1.5 Pro’s multimodal vision model, which is capable of reading embedded text from real-world photos.\\\nThe function opens the image file in binary mode, attaches it to a prompt asking Gemini to extract all visible text (but not translate), and then returns the raw string. This step is useful when the goal is to understand what’s written in a local language before translating or explaining it.\n\n**translate_to_english(text) – Text Translation** 🌐🗣️\\\nOnce the text is extracted from an image, we pass it to this function, which uses Gemini 2.0 Flash to translate it into English. The prompt is simple and direct: translate the following text.\\\nThis lets users take photos of signs, menus, schedules, or maps and instantly understand what they mean — perfect for tourists navigating unfamiliar environments.\\\nFor example: A French street sign like \"Rue des Bourneaux\" → \"Bourneaux Street\"\n\n**describe_photo(file_path) – Landmark and Scene Description** 🏛️✨\\\nThis function goes beyond OCR and answers a higher-level question: “What am I looking at?”\\\nIt uses Gemini 1.5 Pro to analyze the image and describe the scene, including its possible cultural or historical context. It’s especially useful for travel photos like landmarks, public art, or architecture. The prompt instructs Gemini to describe what’s in the image and why it might matter to a traveler — similar to how a museum guide or tour book would explain a location.\\\nFor example: Upload a photo of the Eiffel Tower → “This is the Eiffel Tower in Paris, an iconic symbol of France built for the 1889 World's Fair…”","metadata":{}},{"cell_type":"code","source":"# Extract text from image\ndef extract_text_from_image(file_path: str) -> str:\n    with open(file_path, \"rb\") as img:\n        image_bytes = img.read()\n\n    prompt = \"Extract all visible text from this image. Don't translate it.\"\n\n    response = client.models.generate_content(\n        model=\"gemini-1.5-pro-latest\",\n        contents=[\n            types.Part.from_text(text=prompt),\n            types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\")\n        ]\n    )\n    return response.text.strip()\n\n# Translate extracted text using Geimini Flash\ndef translate_to_english(text: str) -> str:\n    prompt = f\"Translate the following to English:\\n\\n{text}\"\n    \n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n    return response.text.strip()\n\ndef describe_photo(file_path: str) -> str:\n    with open(file_path, \"rb\") as img:\n        image_bytes = img.read()\n\n    prompt = (\n        \"You are a travel assistant. Describe this photo in detail. \"\n        \"Explain what is shown, its possible cultural or historical significance, \"\n        \"and any information that could help a traveler understand what they’re looking at.\"\n    )\n\n    response = client.models.generate_content(\n        model=\"models/gemini-1.5-pro-latest\",\n        contents=[\n            types.Part.from_text(text=prompt),\n            types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\")  # or image/png\n        ]\n    )\n\n    return response.text.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🎟️ Discovering Local Events\nOne of the most exciting travel upgrades in TravelAIAgent is its ability to suggest real events happening in your destination. Whether you’re into concerts, theater, or cultural exhibits, the assistant uses this function to bring your itinerary to life with up-to-date entertainment options — all powered by the Ticketmaster Discovery API and summarized naturally using Gemini.\n\n**get_events(city, start_date, end_date, max_events) – Event Discovery + Summarization**\\\nThis function starts by querying the Ticketmaster Discovery API, using the name of the city and optional start/end date filters. It returns a list of upcoming events sorted by date — concerts, sports, exhibitions, shows, and more. We limit the number of results using max_events (default is 5) to avoid overwhelming the user and focus on the most relevant options. For each event, we extract key info such as name, date, venue\\\nInstead of listing raw data directly to the user, the assistant passes the list to Gemini 2.0 Flash using a well-crafted prompt. Gemini then summarizes the events in a casual, friendly tone — just like a travel agent would.\\\nFor example: “This week in San Francisco: balloon art exhibits, jazz at Birdland, and some Broadway action if you’re feeling theatrical. 🎷🎭”\\\nThe prompt also nudges Gemini to recommend which events suit different travelers (families, art lovers, music fans), highlight variety and uniqueness, and keep the tone fun and helpful","metadata":{}},{"cell_type":"code","source":"def get_events(city: str, start_date: str = None, end_date: str = None, max_events: int = 5) -> str:\n    url = \"https://app.ticketmaster.com/discovery/v2/events.json\"\n\n    params = {\n        \"apikey\": EVENTS_API_KEY,\n        \"city\": city,\n        \"sort\": \"date,asc\",\n        \"locale\": \"*\",\n    }\n\n    if start_date:\n        params[\"startDateTime\"] = start_date\n    if end_date:\n        params[\"endDateTime\"] = end_date\n\n    response = requests.get(url, params=params)\n    if response.status_code != 200:\n        return f\"Sorry, I couldn't fetch events for {city}.\"\n\n    data = response.json()\n    events = data.get(\"_embedded\", {}).get(\"events\", [])[:max_events]\n\n    if not events:\n        return f\"No upcoming events found in {city}.\"\n\n    # Prepare input for Gemini\n    raw_event_lines = []\n    for event in events:\n        name = event.get(\"name\", \"Unnamed Event\")\n        date = event.get(\"dates\", {}).get(\"start\", {}).get(\"localDate\", \"Unknown Date\")\n        venue = event.get(\"_embedded\", {}).get(\"venues\", [{}])[0].get(\"name\", \"Unknown Venue\")\n        line = f\"{name} on {date} at {venue}\"\n        raw_event_lines.append(line)\n\n    event_input = \"\\n\".join(raw_event_lines)\n\n    # Gemini prompt\n    prompt = (\n    f\"You’re a cheerful travel assistant. Summarize these events in {city} in a relaxed, travel-friendly tone. \"\n    f\"Pick out highlights — like concerts, art, festivals, or unique experiences — and suggest what type of traveler they might appeal to.\\n\\n\"\n    f\"{event_input}\"\n    )\n\n\n    summary_response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    return summary_response.text.strip()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔍 Local Insights & Landmark Knowledge\nTo give TravelAIAgent the ability to answer grounded, location-specific questions — like cultural etiquette, local dos and don'ts, or tips about a photo — we use Retrieval Augmented Generation (RAG). This section combines ChromaDB (a vector database), Gemini embeddings, and Gemini's language generation to bring real-world knowledge into the assistant's responses.\n\n**🧳 documents – Curated Travel Tips**\\\nWe start with a hardcoded list of helpful, city-specific cultural tips and travel advice. These act as a lightweight knowledge base. Each item is a short, practical sentence — perfect for answering questions like: “What should I know before going to Tokyo?”, “Is it okay to haggle in Marrakech?”\n\n**🧠 GeminiEmbeddingFunction – Semantic Understanding**\\\nTo search through these tips in a meaningful way, we embed both the tips and the user's queries using Gemini's text-embedding-004 model. This converts text into high-dimensional vectors that capture their semantic meaning. The class supports two modes: \"retrieval_document\" – for indexing passages and \"retrieval_query\" – for embedding the user's question. This ensures the model can retrieve relevant advice even if the user asks in a different phrasing than what’s stored.\n\n**🗃️ chroma_client + chromaDB – Embedding Storage**\\\nWe initialize a ChromaDB collection named \"travel_tips\", embed the list of tips, and store them by unique IDs. This allows the assistant to quickly search for tips that are most relevant to the user's question at runtime.\n\n**❓ search_and_answer(user_question) – RAG Answering**\\\nWhen a user asks for tips or cultural context: The function switches to query mode -> Finds the top 2 semantically similar tips from ChromaDB -> Passes those into Gemini 2.0 Flash using a prompt that instructs it to generate a helpful, grounded answer. This pattern ensures that answers are both relevant and informed by the actual data — a key aspect of building trust in AI assistants.\n\n**🖼️ Image Insights: photo_collection + search_photo_insights()**\\\nWe use the same RAG pipeline to store and query descriptions of user-uploaded photos (e.g. landmarks, statues, monuments). After describing a photo using Gemini Vision, the description is embedded and added to a separate collection (photo_insights). Then, if the user asks: “What is that building?” or “What’s the story behind this statue?”. We use search_photo_insights() to pull relevant image descriptions from the vector DB and let Gemini answer based on that context.\n\n\nTogether, these components turn your assistant into a context-aware, grounded travel expert. It can recall city-specific etiquette, offer photo-based insight, and explain things like a human guide — all while staying efficient and scalable. ✈️🧠📸","metadata":{}},{"cell_type":"code","source":"documents = [\n    \"In Bangkok, visit Chatuchak Market on the weekend and avoid tuk-tuk scams near tourist spots.\",\n    \"In Paris, always greet with 'Bonjour' before asking questions. Most museums are closed on Mondays.\",\n    \"In London, public transport uses contactless cards. Tipping is not expected in pubs.\",\n    \"In Dubai, public displays of affection are discouraged. Dress modestly in public areas.\",\n    \"In Singapore, chewing gum is banned. It’s one of the cleanest and safest cities globally.\",\n    \"In Kuala Lumpur, try nasi lemak for breakfast. Petronas Towers are best viewed at sunset.\",\n    \"In New York City, walk fast, tip 15–20%, and explore boroughs beyond Manhattan.\",\n    \"In Istanbul, try local ferry rides and visit both European and Asian sides of the city.\",\n    \"In Tokyo, avoid loud phone calls on trains. Convenience stores (konbini) have everything.\",\n    \"In Antalya, the old town (Kaleiçi) is walkable and filled with ancient Roman ruins.\",\n    \"In Seoul, Korean street food markets like Gwangjang are must-visit. Public transport is efficient.\",\n    \"In Rome, beware of pickpockets at popular landmarks. Tap water is drinkable.\",\n    \"In Phuket, island tours are best booked locally. Avoid animal-based attractions.\",\n    \"In Mecca, non-Muslims cannot enter the central holy area. Stay hydrated in the heat.\",\n    \"In Hong Kong, use the Octopus card for transport and street food. Don't miss Victoria Peak.\",\n    \"In Barcelona, be cautious of pickpockets on Las Ramblas. Tapas culture is big—dine late.\",\n    \"In Zurich, trains are punctual to the minute. Public water fountains offer safe drinking water.\",\n    \"In Cairo, tipping (baksheesh) is expected for most services. Visit the pyramids early to avoid crowds.\",\n    \"In Sydney, sun protection is essential year-round. Use an Opal card for public transport.\",\n    \"In Marrakech, haggle respectfully in souks. Fridays are holy—many shops may close.\",\n    \"In Amsterdam, watch for bikes at crossings. Many museums require advance reservations.\",\n    \"In Mexico City, avoid tap water. Street tacos are a must, but go where locals eat.\",\n    \"In Athens, the Acropolis is best visited early morning. Tipping is appreciated but not required.\",\n    \"In Vancouver, use contactless or Compass Card for transit. Pack for rain, even in summer.\",\n    \"In Buenos Aires, late dinners and tango shows are local staples. Beware of counterfeit currency.\",\n    \"In Prague, the Old Town is stunning but crowded—explore Žižkov and Letná for a local vibe.\",\n    \"In Vienna, classical concerts abound, but dress semi-formally. Public transport is safe and clean.\",\n    \"In Cape Town, avoid walking after dark in certain areas. Visit Table Mountain on a clear day.\",\n    \"In Lisbon, trams can get crowded—beware of pickpockets. Try pastel de nata from local bakeries.\",\n    \"In Los Angeles, public transport is limited—consider renting a car. Tipping is standard at 20%.\"\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gemini Embedding Function class\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input):\n        task_type = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(task_type=task_type)\n        )\n        return [e.values for e in response.embeddings]\n\n# Initialize ChromaDB\nchroma_client = chromadb.Client()\nDB_NAME = \"travel_tips\"\nembed_fn = GeminiEmbeddingFunction()\n\ndb = chroma_client.get_or_create_collection(\n    name=DB_NAME,\n    embedding_function=embed_fn\n)\n\n# Store tips\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n\n# Search and answer\ndef search_and_answer(user_question):\n    # Switch to query embedding mode\n    embed_fn.document_mode = False\n\n    # Search top matching passage\n    result = db.query(query_texts=[user_question], n_results=2)\n    passages = result[\"documents\"][0]\n\n    # Create grounded prompt for Gemini\n    prompt = (\n        \"You are a helpful travel assistant. Use the information from the following passages \"\n        \"to answer the user's question clearly. If irrelevant, ignore it.\\n\\n\"\n        f\"QUESTION: {user_question}\\n\"\n    )\n\n    for p in passages:\n        prompt += f\"PASSAGE: {p.strip()}\\n\"\n\n    # Generate response\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n    return response.text\n\n# Store image description with ChromaDB\nphoto_collection = chroma_client.get_or_create_collection(\n    name=\"photo_insights\",\n    embedding_function=embed_fn\n)\n\ndef add_photo_description_to_chromadb(photo_id: str, description: str):\n    photo_collection.add(\n        documents=[description],\n        ids=[photo_id]\n    )\n\n# Search photo description with a question\ndef search_photo_insights(user_question: str, top_k: int = 2) -> str:\n    embed_fn.document_mode = False  # use query embedding\n\n    results = photo_collection.query(query_texts=[user_question], n_results=top_k)\n    matches = results[\"documents\"][0]\n\n    prompt = (\n        \"You are a helpful travel assistant. Use the following descriptions to answer the user's question.\\n\\n\"\n        f\"QUESTION: {user_question}\\n\"\n    )\n\n    for desc in matches:\n        prompt += f\"DESCRIPTION: {desc.strip()}\\n\"\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n    return response.text.strip()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🧠 Modular Intent Handlers\nTo keep TravelAIAgent organized and extensible, every user intent is handled by a dedicated function — known as a “handler.” These functions make the assistant more maintainable and allow for clear separation of logic, especially when integrating multiple tools like weather APIs, image understanding, vector search, and LLM generation.\\\nEach handler performs three key tasks:\n1. Executes a specific capability (like getting weather or generating an itinerary)\n2. Updates the assistant’s memory if needed (e.g. storing the last mentioned city)\n3. Prints and stores the response in the conversation history\n\n---\n\n**🌤️ handle_get_weather & handle_get_weather_forecast**\\\nThese handlers fetch current conditions or a 5-day forecast from OpenWeather and summarize it using Gemini. They store the city as memory[\"last_city\"] so the assistant can reference it later when the user says, “What’s the weather like there?”\n\n**🧳 handle_get_tip**\\\nThis pulls grounded cultural advice from ChromaDB using a RAG-style query. It also extracts and stores the city mentioned in the user’s tip-related question to maintain context.\n\n**📸 handle_describe_photo, handle_ask_about_photo, handle_image_translate**\\\nThese three handlers handle photo-related requests:\n1. describe_photo: Uses Gemini Vision to describe what’s in an uploaded image (e.g. a statue or landmark)\n2. ask_about_photo: Allows follow-up questions using photo-based RAG from ChromaDB\n3. image_translate: Extracts and translates visible text from a photo (e.g. street signs or menus)\nThey help users understand and interact with their surroundings more easily, especially in unfamiliar places.\n\n**🌆 handle_get_events**\\\nThis fetches events in a city using the Ticketmaster Discovery API and summarizes them using Gemini. The results feel natural and tailored — great for finding things to do on the fly.\n\n**🗺️ handle_plan_itinerary**\\\nThis is one of the most impressive handlers — it builds a personalized, multi-day itinerary using:\n1. Weather forecasts\n2. Cultural travel tips (from ChromaDB)\n3. User preferences (stored throughout the session)\nIt crafts a prompt that instructs Gemini to combine all that information into a casual, smart itinerary.\n\n**🧠 handle_get_weather_last & handle_get_last_city**\\\nThese support context-awareness. If the user asks: “What’s the weather like there?” or “Which city was I talking about?”. The assistant responds intelligently based on the memory dictionary (memory[\"last_city\"]), maintaining a natural and coherent conversation flow.\n","metadata":{}},{"cell_type":"code","source":"# Handlers\ndef handle_get_weather(action, history, memory):\n    city = action[\"location\"]\n    memory[\"last_city\"] = city\n    weather_info = get_weather(city)\n    print(\"AI:\", weather_info)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=weather_info)]))\n\n\ndef handle_get_tip(action, history, memory):\n    query = action[\"query\"]\n    city = extract_city_from_text(query)\n    memory[\"last_city\"] = city if city else query\n    tip_answer = search_and_answer(query)\n    print(\"AI:\", tip_answer)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=tip_answer)]))\n\n\ndef handle_describe_photo(action, history):\n    filename = action[\"filename\"]\n    filepath = f\"/kaggle/input/photoss/{filename}\"\n\n    try:\n        with open(filepath, \"rb\") as f:\n            f.read(1)\n        if filename not in photo_collection.get()['ids']:\n            description = describe_photo(filepath)\n            add_photo_description_to_chromadb(photo_id=filename, description=description)\n            print(\"AI: Here's what I see in that photo:\")\n            print(description)\n            history.append(types.ModelContent(parts=[types.Part.from_text(text=description)]))\n        else:\n            print(f\"AI: I already have a description for `{filename}`.\")\n    except FileNotFoundError:\n        print(f\"AI: I couldn't find the image `{filename}` in /kaggle/input/photoss/.\")\n\n\ndef handle_ask_about_photo(user_input, history):\n    if not photo_collection.get()['documents']:\n        print(\"AI: I haven’t analyzed any photos yet. Ask me to describe one first.\")\n        return\n    photo_answer = search_photo_insights(user_input)\n    print(\"AI:\", photo_answer)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=photo_answer)]))\n\n\ndef handle_image_translate(action, history):\n    filename = action[\"filename\"]\n    filepath = f\"/kaggle/input/photoss/{filename}\"\n\n    try:\n        raw_text = extract_text_from_image(filepath)\n        if not raw_text or raw_text.lower() in [\"none\", \"\"]:\n            print(\"AI: I couldn't read any text from the image.\")\n            return\n\n        translated = translate_to_english(raw_text)\n        print(\"AI: Here's the translated text from the image:\")\n        print(translated)\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=translated)]))\n    except FileNotFoundError:\n        print(f\"AI: I couldn't find `{filename}`. Upload it to /kaggle/input/photoss/.\")\n\n\ndef handle_get_weather_last(memory, history):\n    if memory[\"last_city\"]:\n        city = memory[\"last_city\"]\n        weather_info = get_weather(city)\n        print(f\"AI: Here's the latest weather in {city}:\\n{weather_info}\")\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=weather_info)]))\n    else:\n        print(\"AI: I don't know your last mentioned city yet.\")\n\n\ndef handle_get_last_city(memory, history):\n    if memory[\"last_city\"]:\n        print(f\"AI: The last city you mentioned was {memory['last_city']}.\")\n        history.append(types.ModelContent(parts=[types.Part.from_text(text=memory['last_city'])]))\n    else:\n        print(\"AI: You haven't mentioned a city yet.\")\n\ndef handle_get_weather_forecast(action, memory, history):\n    city = action[\"location\"]\n    memory[\"last_city\"] = city\n    forecast = get_weather_summary(city)\n    print(\"AI:\", forecast)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=forecast)]))\n\ndef handle_plan_itinerary(action, memory, history):\n    city = action[\"location\"]\n    days = action.get(\"days\", 3)\n    when = action.get(\"when\", \"next week\")\n    memory[\"last_city\"] = city\n\n    # Get forecast summary (multi-day, formatted)\n    forecast = get_weather_summary(city)\n\n    # Get cultural tips\n    tips = search_and_answer(f\"travel tips for {city}\")\n\n    # Combine prompt\n    user_prefs = \"\\n\".join(memory[\"preferences\"]) if memory[\"preferences\"] else \"No specific preferences given.\"\n\n    prompt = (\n        f\"You are a friendly travel planner. Create a detailed day-by-day travel itinerary for {city} for {days} days starting {when}.\\n\"\n        f\"Use the weather forecast, travel tips, and user preferences below:\\n\\n\"\n        f\"Weather:\\n{forecast}\\n\\n\"\n        f\"Cultural Tips:\\n{tips}\\n\\n\"\n        f\"User Preferences:\\n{user_prefs}\\n\\n\"\n        f\"Return a helpful, conversational itinerary. If a day is rainy, suggest more indoor activities. Mention why each activity fits the user’s interests.\"\n    )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_text(text=prompt)]\n    )\n\n    itinerary = response.text.strip()\n    print(\"AI:\", itinerary)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=itinerary)]))\n\n# Get events info\ndef handle_get_events(action, history, memory):\n    city = action[\"location\"]\n    memory[\"last_city\"] = city\n\n    today = datetime.datetime.utcnow()\n    next_week = today + datetime.timedelta(days=7)\n    start = today.strftime(\"%Y-%m-%dT00:00:00Z\")\n    end = next_week.strftime(\"%Y-%m-%dT23:59:59Z\")\n\n    events_info = get_events(city=city, start_date=start, end_date=end)\n    print(\"AI:\", events_info)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=events_info)]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 💬 **Chat with TravelAIAgent**\nThis block of code powers the entire real-time conversation between the user and TravelAIAgent. It’s where everything comes together — intent recognition, memory tracking, handler dispatching, and fallback chat. Here's how it works:\n\n---\n\n**🕘 history and memory Initialization**\\\nThe assistant starts with two critical variables:\n1. history: a list that stores the full back-and-forth conversation (in Gemini’s expected format). It keeps context across turns.\n2. memory: a dictionary that stores session-specific context like: last_city: the most recently mentioned city (used for follow-ups like \"What's the weather like there?\"), and  preferences: any user-specified likes (e.g. “I love seafood”) that guide future responses\n\n---\n**👋 First Impression: Onboarding Message**\\\nThe assistant prints a warm welcome using the onboarding_message and also adds it to the conversation history. This sets the tone and immediately informs the user of the assistant’s capabilities.\n\n---\n\n**🔁 The Main Loop**\\\nThis is a while True: loop that simulates ongoing conversation. Each time the user enters input: User message is read and cleaned, and intent is interpreted using interpret_user_request()\n\nThe assistant routes the request to the appropriate handler: Weather, Cultural tips, Photo analysis, Event search, Itinerary planning, Translation, Memory recall, Handlers take care of fetching data, calling APIs, or prompting Gemini, then store the result back in history.\n\n---\n\n**🧠 Fallback Branch**\\\nIf none of the intent matches are triggered (e.g. the user says something casual or vague): The input is added to history, Gemini is called with full context to continue the conversation naturally. Optionally, if the user shares a preference (e.g. \"I love museums\"), it’s stored in memory[\"preferences\"] for future personalization. A try/except block ensures any Gemini API failures are handled gracefully without breaking the loop — offering a friendly error instead of a crash.","metadata":{}},{"cell_type":"code","source":"def start_travel_chat():\n    history = []\n    memory = {\n        \"last_city\": None,\n        \"preferences\": []\n    }\n\n    print(\"TravelAI:\", onboarding_message)\n    history.append(types.ModelContent(parts=[types.Part.from_text(text=onboarding_message)]))\n\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'q':\n            print(\"Goodbye!\")\n            break\n\n        action = interpret_user_request(user_input)\n\n        if action.get(\"intent\") == \"get_weather\" and \"location\" in action:\n            handle_get_weather(action, history, memory)\n        elif action.get(\"intent\") == \"get_tip\" and \"query\" in action:\n            handle_get_tip(action, history, memory)\n        elif action.get(\"intent\") == \"describe_photo\" and \"filename\" in action:\n            handle_describe_photo(action, history)\n        elif action.get(\"intent\") == \"ask_about_photo\" and \"question\" in action:\n            handle_ask_about_photo(user_input, history)\n        elif action.get(\"intent\") == \"image_translate\" and \"filename\" in action:\n            handle_image_translate(action, history)\n        elif action.get(\"intent\") == \"get_weather_last\":\n            handle_get_weather_last(memory, history)\n        elif action.get(\"intent\") == \"get_last_city\":\n            handle_get_last_city(memory, history)\n        elif action.get(\"intent\") == \"get_weather_forecast\" and \"location\" in action:\n            handle_get_weather_forecast(action, memory, history)\n        elif action.get(\"intent\") == \"plan_itinerary\" and \"location\" in action:\n            handle_plan_itinerary(action, memory, history)\n        elif action.get(\"intent\") == \"get_events\" and \"location\" in action:\n            handle_get_events(action, history, memory)\n        else:\n            if user_input:\n                history.append(types.UserContent(parts=[types.Part.from_text(text=user_input)]))\n\n                if any(phrase in user_input.lower() for phrase in [\"i like\", \"i prefer\", \"i enjoy\", \"i love\", \"i want\"]):\n                    memory[\"preferences\"].append(user_input)\n\n                try:\n                    response = client.models.generate_content(\n                        model=\"gemini-2.0-flash\",\n                        config=config,\n                        contents=history\n                    )\n                    history.append(response.candidates[0].content)\n                    print(\"AI:\", response.text)\n                except Exception as e:\n                    print(\"⚠️ AI: I had trouble generating a response. Please try rephrasing.\")\n                    print(\"Error:\", str(e))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feel free to run following code and start chatting to TravelAIAgent!\nTo begin your travel planning session, just run the cell below. Type naturally — like you're talking to a friend — and ask anything about your destination. Type `q` to exit the chat anytime.","metadata":{}},{"cell_type":"code","source":"start_travel_chat()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}